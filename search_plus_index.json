{"./":{"url":"./","title":"Introduction","keywords":"","body":"1. 个人的一些秋招总结1. 个人的一些秋招总结 目录 https://jns0724.github.io/my-summary/ By JNS0724            updated 2022-08-28 13:37:21 "},"cpp/stl.html":{"url":"cpp/stl.html","title":"Stl","keywords":"","body":"1. STL组件1.1. 六大组件1.2. allocator1.2.1. std_construct.h1.2.2. allocator.h1.3. Type_traits1.4. vector1.5. list1.6. deque1.6.1. 初始化1.6.2. 迭代器1.7. stack1.8. queue1.9. priority_queue1.10. unordered_map1.11. 仿函数 函数对象1.12. 配接器（adapters）1. STL组件 1.1. 六大组件 容器\\算法\\迭代器\\仿函数\\adapter\\allocator 1.2. allocator 头文件memory分为allocator.h和std_construct.h两个头文件，construct里的constrcut函数用来调用placement new 1.2.1. std_construct.h construct() 调用placement new初始化 destory() 用type_trait判断是否需要调用析构函数，需要的话即调用。 1.2.2. allocator.h 定义了allocator class继承于allocator_base,allocator_base默认就是new_allocator 因此std::allocator默认就是new_allocator,new_allocator调用的是全局的::operator new 1.3. Type_traits 一种类型萃取的技巧, 具体实现是通过模板匹配,获得参数类型信息,根据模板偏特化来进行特殊处理. 1.4. vector 具体实现: struct _Vector_impl_data { pointer _M_start; // 使用空间头位置 pointer _M_finish; // 使用空间尾位置 pointer _M_end_of_storage; // 可用空间的结尾 //... } // 扩容 _M_check_len(size_type __n, const char* __s) const { //... // 获得新长度 这里取当前使用的空间大小和需要的大小作比较, 作为扩容的大小. const size_type __len = size() + (std::max)(size(), __n); return (__len max_size()) ? max_size() : __len; //... } 普通的push_back就是1->2->4的两倍扩容 resize(n): 这里看三个参数: size: 实际使用的容量 n: 想要填充到这么多 capacity: 数组所占的内存大小 如果 n > size, 则扩容到 size + n, 扩容后size = size + n, capacity = size + n; 如果 n 如果n比原来的capacity小的话,就是size = n,capacity不变,也就是不会缩容. reverse(n):就是把capacity扩到n,其他不变 不过不管咋说,扩容都是要重新分配内存. 1.5. list 环形双向链表,尾部多一个节点. 插入删除不会使原来的迭代器失效. 1.6. deque 一段段定量连续空间串联起来的队列. 1.6.1. 初始化 默认创建8块内存块,每个内存块默认512字节,如果一个元素大于512字节,则一个元素占一块. 头尾节点不用. _M_initialize_map(size_t __num_elements) { const size_t __num_nodes = (__num_elements/ __deque_buf_size(sizeof(_Tp)) + 1); // 需要多少内存块 this->_M_impl._M_map_size = std::max((size_t) _S_initial_map_size, size_t(__num_nodes + 2)); // 默认8块 加2是因为头尾不用 this->_M_impl._M_map = _M_allocate_map(this->_M_impl._M_map_size); // 申请内存 // For \"small\" maps (needing less than _M_map_size nodes), allocation // starts in the middle elements and grows outwards. So nstart may be // the beginning of _M_map, but for small maps it may be as far in as // _M_map+3. _Map_pointer __nstart = (this->_M_impl._M_map + (this->_M_impl._M_map_size - __num_nodes) / 2); // 就是头节点的下一个节点 _Map_pointer __nfinish = __nstart + __num_nodes; // 尾节点的前一个节点 __try { _M_create_nodes(__nstart, __nfinish); } __catch(...) { _M_deallocate_map(this->_M_impl._M_map, this->_M_impl._M_map_size); this->_M_impl._M_map = _Map_pointer(); this->_M_impl._M_map_size = 0; __throw_exception_again; } this->_M_impl._M_start._M_set_node(__nstart); this->_M_impl._M_finish._M_set_node(__nfinish - 1); this->_M_impl._M_start._M_cur = _M_impl._M_start._M_first; this->_M_impl._M_finish._M_cur = (this->_M_impl._M_finish._M_first + __num_elements % __deque_buf_size(sizeof(_Tp))); } 1.6.2. 迭代器 _Elt_pointer _M_cur; 块内当前位置 _Elt_pointer _M_first; 块内第一个元素位置 _Elt_pointer _M_last; 块内最后一个元素位置 _Map_pointer _M_node; 当前内存块 通过这几个指针,迭代器实现在内存块中去跳转. 1.7. stack 只能从一端进出,默认以deque为底层实现.可以更换为list. 1.8. queue 一端进一端出,默认以deque为底层实现,可以更换为list. 1.9. priority_queue 优先队列,通常用来实现最大最小堆.底层实现默认是vector. 1.10. unordered_map 底层实现是hashtable,解决哈希冲突是拉链法,在槽中是头插法. 扩容:初始为槽容量11除以最大负载因子(默认为1.0), 由于结果可能不整除,所以默认都要加上1,然后再取比12大的质数13. 即初始槽数为13 每次扩容都是乘以2,再找比其大的质数. 如果不够放,就用(原有元素个数+已有元素个数 ) / 最大负载因子 ,再去求比其大的质数. _M_need_rehash(std::size_t __n_bkt, std::size_t __n_elt, std::size_t __n_ins) const { if (__n_elt + __n_ins > _M_next_resize) { // If _M_next_resize is 0 it means that we have nothing allocated so // far and that we start inserting elements. In this case we start // with an initial bucket size of 11. double __min_bkts = std::max(__n_elt + __n_ins, _M_next_resize ? 0 : 11) / (double)_M_max_load_factor; if (__min_bkts >= __n_bkt) return { true, _M_next_bkt(std::max(__builtin_floor(__min_bkts) + 1, __n_bkt * _S_growth_factor)) }; _M_next_resize = __builtin_floor(__n_bkt * (double)_M_max_load_factor); return { false, 0 }; } else return { false, 0 }; } 扩容: // Rehash when there is no equivalent elements. template void _Hashtable:: _M_rehash_aux(size_type __n, std::true_type) { __bucket_type* __new_buckets = _M_allocate_buckets(__n); // 新的bucket数组 __node_type* __p = _M_begin(); // 首个节点 _M_before_begin._M_nxt = nullptr; std::size_t __bbegin_bkt = 0; while (__p) { // 开始迁移该节点 __node_type* __next = __p->_M_next(); // 先获取下一个节点 std::size_t __bkt = __hash_code_base::_M_bucket_index(__p, __n); // 计算插入的桶下标 if (!__new_buckets[__bkt]) { // 空桶的话,这个_p将会是这个桶链表里的最后一个节点,因此让它指向_M_before_begin.next // 也就是迭代器的首个节点,然后自己成为迭代器的_M_before_begin.next,这样保证rehash之 // 后,所有的非空桶都能串起来 __p->_M_nxt = _M_before_begin._M_nxt; _M_before_begin._M_nxt = __p; __new_buckets[__bkt] = &_M_before_begin; if (__p->_M_nxt) __new_buckets[__bbegin_bkt] = __p; __bbegin_bkt = __bkt; } else { // 非空桶,头插法 __p->_M_nxt = __new_buckets[__bkt]->_M_nxt; __new_buckets[__bkt]->_M_nxt = __p; } __p = __next; } _M_deallocate_buckets(); _M_bucket_count = __n; _M_buckets = __new_buckets; } 1.11. 仿函数 函数对象 通过重载调用操作符模仿函数调用的类,可以称为仿函数 函数对象. 比起普通函数 函数指针,更有抽象性 既有函数调用的功能,又有类的抽象,可以存储自身状态,易扩展. 1.12. 配接器（adapters） 用来修饰容器，仿函数或者迭代器的接口,使原来不相互匹配的两个类可以相互匹配 By JNS0724            updated 2022-08-28 13:37:21 "},"cpp/内存管理.html":{"url":"cpp/内存管理.html","title":"内存管理","keywords":"","body":"1. 内存管理1.1. 内存分配1.1.1. new和malloc的区别1.1.2. array new 和 array delete1. 内存管理 malloc和free是glibc标准C库提供的,glibc是对系统调用的封装 new和delete是编译器的标准c++库提供的,对于gcc编译器就是libstdc++,对于clang就是libc++. 1.1. 内存分配 1.1.1. new和malloc的区别 malloc仅仅开辟内存，new开辟内存之后还调用构造函数初始化。 new对应的两个步骤为operator new和placement new，分别对应开辟内存和在内存上初始化。 operator new本质上就是对与malloc的封装。 new关键字会被编译器替换成operator new和构造函数。 1.1.2. array new 和 array delete 底层也是operator new和多次的构造函数，数组在外层和每个元素内层都有一个cookie标记内存信息。 By JNS0724            updated 2022-08-28 13:37:21 "},"cpp/常用关键字.html":{"url":"cpp/常用关键字.html","title":"常用关键字","keywords":"","body":"1. 常用关键字1.1. static1.2. const & constexpr1.2.1. const表示静态属性1.2.2. constexpr1.3. this指针1.4. inline1.5. volatile1.6. union1.7. auto1. 常用关键字 1.1. static 静态属性 普通变量：改变变量的生命周期和存储区域，位于静态数据段。 普通函数：声明函数的作用范围限定在类文件里，避免重名。 成员变量：声明类里只能保存一个该变量，不需要实例化就能访问。 成员函数：不需要实例化就能访问，只能调用static成员。 1.2. const & constexpr 1.2.1. const表示静态属性 修饰变量，表示变量不可变 const指针有两种，指向指针内容和指针本身 int x = 10; const int* p = &x; //指针内容不能变，也就是x的值 int* const p = &x; //指针不能变，也就是只能指向p const成员函数，表示不能修改成员变量 const和define宏定义常量的区别 const define 编译器处理 预处理器处理 类型安全检查 无类型检查 需要分配内存 不需要分配内存 存储在数据段 存储在代码段 不可取消 可以用#undef取消 可以看出const是编译层面上的常量，是一种类型，而define实际上只是宏的应用，是文本的替换。 1.2.2. constexpr c++11引入，编译期常量，表示在编译期完成计算。 修饰函数，一般是一些计算的函数，调用时在编译期完成计算并替换成常量。 修饰变量，只能修饰在编译期就能确定的变量。只能修饰基础类型和指针、引用，但我们可以定义一个类，其构造函数修饰为constexpr，则可以在编译期完成 1.3. this指针 this指针式隐含于每一个非静态成员函数的特殊指针，指向调用该成员函数的对象。this指针隐含在成员函数的参数列表中的首个位置。 this指针隐式声明为ClassName *const this，不能修改this指针的指向。同时this是右值，不能获取this的地址。 1.4. inline 内联函数，直接在调用处执行函数体，免去函数跳转和函数栈帧的开销。在类声明中定义的函数，除了虚函数，都隐式地当成内联函数。inline是对编译器的建议，编译器不会内联包含循环、递归、switch等复杂动作。编译器会把函数体复制到调用处，然后为inline函数局部变量分配内存，将inline函数的输入参数和返回值映射到调用处的函数的局部变量空间中，如果inline函数有多个return，转变为inline函数代码块末尾的分支。 对比宏，inline有类型检查。 虚函数可以是内联函数，但表现多态性时除外。内联是编译期的动作，不能在运行期内联。 1.5. volatile 声明为volatile的变量，表示禁止编译器优化，编译器不会把volatile变量当作常量消灭掉，也不会把volatile变量的值缓存在寄存器里。作为一个sequence point，阻止编译器在重排operator的时候跨越这个点。但volatile不能阻止cpu的指令重排序。 不能作为多线程同步的手段，多线程同步应该依赖atomic原子操作和锁。 要实现多线程共享变量的同步，需要同时实现指令屏障、内存屏障和编译器屏障。一个知乎回答 1.6. union union中的一组数据成员，只有一个有值，其他都属于未定义状态，内存空间按最大的数据成员来开辟。 1.7. auto auto推导规则和模板参数类似。 template void f(T&& param); // 参数是通用引用 auto x = 27; // auto对应了T const auto cx = x; const auto& rx = x; 唯一的区别在于auto对于{...}类型将推导为std::initializer_list。 By JNS0724            updated 2022-08-28 13:37:21 "},"cpp/新特性总结.html":{"url":"cpp/新特性总结.html","title":"新特性总结","keywords":"","body":"1. 新特性1.1. c++ 111.2. c++ 141.3. c++ 171.4. C++ 201. 新特性 1.1. c++ 11 auto关键字 右值引用 移动语义 完美转发 返回值优化 std::function和lambda表达式 智能指针 1.2. c++ 14 返回值类型推导 constexpr可以使用局部变量和循环 make_unique 1.3. c++ 17 模板类类型自动推导 内联变量，解决静态成员在头文件不能初始化。 constexpr lambda表达式 namespace嵌套 1.4. C++ 20 协程 By JNS0724            updated 2022-08-28 13:37:21 "},"cpp/智能指针.html":{"url":"cpp/智能指针.html","title":"智能指针","keywords":"","body":"1. 智能指针1.1. shared_ptr1.1.1. EBO 优化1.1.2. 线程安全1.2. unique_ptr1. 智能指针 1.1. shared_ptr 通过引用计数来管理指针内存，计数为0时则释放内存。 shared_ptr继承了一个_shared_ptr，这个基类有两个成员函数，实例指针和引用计数控制块_M_refcount。 通过引用计数块来负责管理计数和内存。 引用计数块继承了_Sp_counted_base基类，提供了两个原子计数。 _Atomic_word _M_use_count; // #shared _Atomic_word _M_weak_count; // #weak + (#shared != 0) 并且提供了对计数的加减等操作。 这里模板参数用了__default_lock_policy策略，这个宏是根据有没有开启多线程，来选择锁策略。 引用计数控制块有三种： _Sp_counted_ptr默认的只有引用计数和数据块的指针 _Sp_counted_deleter带自定义删除器的 _Sp_counted_ptr_inplace由make_shared创建的 share_ptr拷贝构造时计数会加1，赋值构造被赋值的会减1，赋值的会加1 template _Assignable operator=(const __shared_ptr& __r) noexcept { _M_ptr = __r._M_ptr; _M_refcount = __r._M_refcount; return *this; } __shared_count& operator=(const __shared_count& __r) noexcept { _Sp_counted_base* __tmp = __r._M_pi; if (__tmp != _M_pi) { if (__tmp != nullptr) __tmp->_M_add_ref_copy(); // 这个加1 if (_M_pi != nullptr) _M_pi->_M_release(); // 这个减1 _M_pi = __tmp; } return *this; } 1.1.1. EBO 优化 shared_ptr的EBO优化，内存分配器和自定义删除器都是继承了_Sp_ebo_helper类，EBO优化降低内存占用。 // Support for custom deleter and/or allocator template class _Sp_counted_deleter final : public _Sp_counted_base { class _Impl : _Sp_ebo_helper, _Sp_ebo_helper { typedef _Sp_ebo_helper _Del_base; typedef _Sp_ebo_helper _Alloc_base; public: _Impl(_Ptr __p, _Deleter __d, const _Alloc& __a) noexcept : _Del_base(std::move(__d)), _Alloc_base(__a), _M_ptr(__p) { } _Deleter& _M_del() noexcept { return _Del_base::_S_get(*this); } _Alloc& _M_alloc() noexcept { return _Alloc_base::_S_get(*this); } _Ptr _M_ptr; }; _M_dispose 删除指针 _M_destroy 析构this类 1.1.2. 线程安全 引用计数用的原子类，是线程安全的。但是指向的数据内容本身不会保护，是非线程安全的。 1.2. unique_ptr 1、独享所有权的智能指针，无法复制构造、赋值操作，只能移动。无法使两个unique_ptr指向同一个对象； 2、unique_ptr智能指向一个对象，如果当它指向其他对象时，之前所指向的对象会被摧毁。 3、unique_ptr对象会在它们自身被销毁时使用删除器自动删除它们管理的对象。 4、unique_ptr支持创建数组对象方法。 release();//放弃控制权，返回裸指针，并将up置为空 reset();//释放up指向的对象 By JNS0724            updated 2022-08-28 13:37:21 "},"cpp/编译链接.html":{"url":"cpp/编译链接.html","title":"编译链接","keywords":"","body":"1. 编译链接1.1. ELF1.2. 链接过程1.3. 动态链接1.3.1. GOT Global Offset Table1.3.2. PLT Procedure Link Table1.4. 堆栈帧1. 编译链接 编译的四个阶段： 预处理-》编译-》汇编-》链接 预处理： 将头文件代码引入 宏替换 删除注释 添加行号和文件标识 .c -> .i 编译：词法分析、语法分析、语义分析，转换成汇编语言 汇编：将汇编语言转换为机器码，生成目标文件。 链接：链接合并其他目标文件。生成可执行文件。 1.1. ELF Executable and Linking Format可执行文件格式 .text 代码段，就是程序指令 .rodata 只读数据，如c语言代码中的字符串 .data 数据段 初始化的全局变量 .bss 未初始化的全局数据，被初始化为0 1.2. 链接过程 1.地址与空间分配 目标文件合并: 相似段合并, 比如代码段和代码段合并. 链接器会收集输入目标文件中的符号定义和引用,形成全局的符号表,同时计算每个段的地址. 2.符号解析 3.重定位 1.3. 动态链接 https://github.com/iqiyi/xHook/blob/master/docs/overview/android_plt_hook_overview.zh-CN.md 1.3.1. GOT Global Offset Table 全局偏移表 存储着外部符号的实际地址偏移量 存在的原因是, 动态链接时,不能直接修改代码段,只能在数据段生成这样的一张表,等查到符号的相对地址后回写到此表中,根据地址去计算实际的外部符号的地址. elf对got做了细分：got存放全局变量引用的地址，got.plt存放函数引用的地址 1.3.2. PLT Procedure Link Table 程序链接表 实现延迟绑定的机制,plt存储的是代码片段,用来跳转到可以帮助我们寻址的_dl_runtime_resolve. 有两个功能 从.got.plt中得到地址,并跳转 触发链接器找到所需地址. 动态库函数第一次调用:xxx@plt -> xxx@got.plt(由于第一次访问,存储地址的是跳转回来) -> common@plt -> _dl_runtime_resolve 做地址解析. 然后将地址回写到GOT中,并返回地址回到调用处. 1.4. 堆栈帧 函数的返回地址和参数 临时变量,非静态局部变量和编译器生成的其他临时变量 保存的上下文,函数前后保持不变的寄存器 By JNS0724            updated 2022-08-28 13:37:21 "},"cpp/语言特性.html":{"url":"cpp/语言特性.html","title":"语言特性","keywords":"","body":"1. 语言特性1.1. 指针和引用的区别1.2. 通用引用（universal reference）1.3. 模板推导1.3.1. ParamType既不是指针也不是引用1.3.2. ParamType是指针或引用，不是通用引用1.3.3. ParamType是通用引用1.3.4. 总结1.4. 虚函数1.4.1. 虚函数的开销1.5. 左值、右值、纯右值、将亡值、泛左值1.6. 引用折叠1.7. 转发语义1. 语言特性 1.1. 指针和引用的区别 指针是一个变量，存储一个地址。引用是变量别名。 指针可以在定义的时候不初始化，引用必须在定义的时候初始化。 指针可以指向NULL，引用不可以为NULL。 指针初始化之后可以再改变，引用不可以。 1.2. 通用引用（universal reference） 同时满足以下两个条件的引用 才是 universal reference 必须存在类型推导 ParamType 只能为T&&，const T&&都不行。 一般情况下只出现在模板函数和auto这两种情况下。 template void f(T&& param) // univeral reference auto&& t2 = t1; // universal reference 1.3. 模板推导 使用方式: template void f(ParamType param); // declaration or definition f(expr); // caller 主要分三种情况 ParamType 既不是指针也不是引用。 ParamType 是指针或引用，不是通用引用。 ParamType 是通用引用。 1.3.1. ParamType既不是指针也不是引用 这种情况下参数param的类型T可以理解为值传递（param会复制一份expr）时的类型。这意味着： 如果expr是一个引用，忽略引用部分。 如果expr带有const或volatile，忽略const、volatile。 int x = 27; const int cx = x; const int& rx = x; f(x); // T为int f(cx); // T为int f(rx); // T为int 1.3.2. ParamType是指针或引用，不是通用引用 如果expr是一个引用，忽略引用部分。 将expr类型与ParamType进行模式匹配，先确定ParamType，再根据ParamType推导T。 template void f(T& param); int x = 27; const int cx = x; const int& rx = x; f(x); // x是int类型，ParamType类型是int&，所以T是int类型 f(cx); // cx是const int类型，ParamType类型是const int&，所以T是const int类型 f(rx); // rx是const int&类型，忽略引用部分，同cx，ParamType类型是const int&，所以T是const int类型 ---------- template void f(const T& param); int x = 27; const int cx = x; const int& rx = x; f(x); // x是int类型，ParamType类型是const int&，所以T是int类型 f(cx); // cx是const int类型，ParamType类型是const int&，所以T是int类型 f(rx); // rx是const int&类型，忽略引用部分，同cx，ParamType类型是const int&，所以T是int类型 ---------- template void f(T* param); // 参数是指针类型 int x = 27; const int *px = &x; f(&x); // &x是int*类型，ParamType类型是int*，所以T是int类型 f(px); // px是const int*类型，ParamType类型是const int*，所以T是const int类型 1.3.3. ParamType是通用引用 如果expr是左值，那么T和ParamType都是左值引用。这是唯一一种T被推导为引用类型的情形。 如果expr是右值，推导规则与普通引用一致。 template void f(T&& param); // 参数是通用引用 int x = 27; const int cx = x; const int& rx = x; f(x); // x 是左值，所以T和ParamType都是int&类型 f(cx); // cx 是左值，所以T和ParamType都是const int&类型 f(rx); // rx 是左值，所以T和ParamType都是const int&类型 f(27); // 27 是右值，ParamType是int&&类型，所以T是int类型 1.3.4. 总结 ParamType 既不是指针也不是引用时，采用值传递模式，忽略表达式的引用部分、const、volatile。 ParamType 是指针或引用，不是通用引用时，忽略引用部分，进行模式匹配，先确定ParamType，再推导T。 ParamType 是通用引用时，左值特殊对待（T和ParamType都是左值引用）。 数组或函数类型退化成指针，除非用来初始化引用。 1.4. 虚函数 虚函数是通过虚函数表实现的，虚函数表存放在.rodata只读数据段。每个对象的内存首个位置都会生成一个指针，指向虚函数表的位置。 1.4.1. 虚函数的开销 空间开销，每个有虚函数的类都需要生成一张虚函数表，指向实际的位置。 时间开销，多了一次内存寻址，通过虚函数指针找到虚函数表。同时，因为跳转指令，有可能会让cpu的分支预测失败，从而刷新流水线指令，影响cpu的执行效率。 1.5. 左值、右值、纯右值、将亡值、泛左值 将亡值和左值统称为泛左值，将亡值和纯右值称为右值。 1、将亡值(xvalue)，xvalue是C++11新增的概念。将亡值可以理解为通过移动构造其他变量内存空间的方式获取到的值。 将亡值表达式： 1）返回右值引用的函数的调用表达式 2）转换为右值引用的转换函数的调用表达 2、纯右值(pvalue)，如：非引用返回的临时变量、运算表达式产生的临时变量、原始字面量和lambda表达式等属于pvalue； 普通左值引用不能指向右值，但是const左值引用可以，有历史原因吧。 右值引用不能指向左值。常量右值引用也不能指向左值和常量左值，但是通过std::move可以指向。 左值引用和右值引用都可以作为左值和右值，主要依赖于： 当引用作为变量保存，就是左值 其他情况是右值 因此对于右值引用，在传递的时候如果是具名的，就需要使用move语义。 https://zhuanlan.zhihu.com/p/99524127 1.6. 引用折叠 Type& & -> Type& Type& && -> Type& Type&& & -> Type& Type&& && -> Type&& 为了规避一些在c++11看起来合理，又不合法的场景。 template func(T &&a); int a1 = 1; func(a1); T将被推导为T& &&（因为万能引用对左值会推导为引用），根据引用折叠就可以转化为T&。 1.7. 转发语义 转发语义基于右值引用实现。 编译器通过移动语义来替代拷贝操作，让开发者可以创建只移类型的对象，比如std::move std::future和std::thread. move是为解决临时变量赋值时，临时变量拷贝完又释放。所以move负责把左值引用转移成右值引用，从而触发移动构造函数。 如果没有移动构造函数，那move也没有意义，stl的容器都实现了移动构造函数。 forward为了解决模板函数参数类型重载问题。 move和forward 区别就在于move是无条件转换为右值，而forward是完美转发，左值移动后还是左值，右值移动后还是右值。其实根本上是因为在模板中万能引用产生的对象可能是左值也可能是右值，有二义性，所以需要forward来传参。 // 转发左值 /** *先获得类型type，定义_t为左值引用的左值变量，通过static_cast进行强制转换。_Tp&&会s发生引用折叠，当_Tp推导为左值引用，则折叠为_Tp& &&，即_Tp&，推导为右值引用，则为本身_Tp&&,所以froward返回值与static_cast处都为_Tp&&。 */ template constexpr _Tp&& forward(typename std::remove_reference::type& __t) noexcept { return static_cast(__t); } // 转发右值 template constexpr _Tp&& forward(typename std::remove_reference::type&& __t) noexcept { static_assert(!std::is_lvalue_reference::value, \"template argument\" \" substituting _Tp is an lvalue reference type\"); return static_cast(__t); } // move的实现是万能引用推导后，都转换为右值引用。 template constexpr typename std::remove_reference::type&& move(_Tp&& __t) noexcept { return static_cast::type&&>(__t); } std::move()与std::forward()都仅仅做了类型转换而已。真正的移动操作是在移动构造函数或者移动赋值操作符中发生的。 std::move()可以应用于左值(普通的变量int这些使用move与不使用move效果一样)，但这么做要谨慎。因为一旦“移动”了左值，就表示当前的值不再需要了，如果后续使用了该值，产生的行为是未定义。 By JNS0724            updated 2022-08-28 13:37:21 "},"其他/docker.html":{"url":"其他/docker.html","title":"Docker","keywords":"","body":"1. docker1.1. 命名空间1.1.1. 网桥模式1.1.2. chroot1.2. CGroups1.3. 镜像1. docker 基本实现原理：命名空间、CGroups、联合文件系统 1.1. 命名空间 通过Linux命名空间对容器进行隔离。 Linux有两个特殊的进程： pid 为 1 的 /sbin/init 进程 前者负责执行内核的一部分初始化工作和系统配置，也会创建一些类似 getty 的注册进程 pid 为 2 的 kthreadd 进程 负责管理和调度其他的内核进程。 容器内只有pid0和1的进程，是因为命名空间实现了进程隔离。 1.1.1. 网桥模式 docker启动时会有docker0的默认网桥，并为每个容器配置虚拟网卡，所有符合条件的请求都会通过iptables转发到docker0并由网桥分发给对应的机器。 1.1.2. chroot 通过改变当前系统的根目录，我们能够限制用户的权利，在新的根目录下并不能够访问旧系统根目录的结构个文件，也就建立了一个与原系统完全隔离的目录结构。 1.2. CGroups 隔离cpu内存等资源，每一个 CGroup 都是一组被相同的标准和参数限制的进程，不同的 CGroup 之间是有层级关系的，也就是说它们之间可以从父类继承一些用于限制资源使用的标准和参数。 1.3. 镜像 Docker 镜像其实本质就是一个压缩包 By JNS0724            updated 2022-08-28 13:37:21 "},"其他/gdb.html":{"url":"其他/gdb.html","title":"Gdb","keywords":"","body":" By JNS0724            updated 2022-08-28 13:37:21 "},"其他/HashMap.html":{"url":"其他/HashMap.html","title":"Hash Map","keywords":"","body":"1. 各种HashMap的实现1.1. Hashmap一些因素1.2. java Hashmap1. 各种HashMap的实现 1.1. Hashmap一些因素 hash函数、冲突解决、扩容机制 1.2. java Hashmap By JNS0724            updated 2022-08-28 13:37:21 "},"其他/场景题.html":{"url":"其他/场景题.html","title":"场景题","keywords":"","body":"1. 场景题1.1. 数据从网卡到socket的过程1.2. 输入URL到页面打开的全过程1. 场景题 1.1. 数据从网卡到socket的过程 1.数据到达网卡，网卡将数据帧通过DMA的方式，发送到RingBuffer，然后发起硬件中断。 2.CPU处理硬件中断，关闭中断表示将开始处理中断。然后发起软件中断。硬中断在哪个cpu，软中断就发生在哪个cpu。 3.内核进程调用网卡驱动注册的poll函数来从ringbuffer读取数据包，并转为skb格式。然后创建skb描述符，将数据拷贝到sk_buffer这个内核里的队列。 4.进入内核协议栈处理，ip_rcv、udp_rcv或者tcp_rcv。 5.将数据拷贝到用户态。 1.2. 输入URL到页面打开的全过程 浏览器匹配缓存的url，解析hosts文件是否有对应的ip地址。 发起DNS请求，查询ip地址。dns服务器像根域名服务器、一级域名服务器逐级查询。 向80端口建立tcp连接，发送http报文。 经过内核协议栈过滤和封装成帧。发送到对端。 对端解析http协议，封装响应报文，发送对应文件资源。 By JNS0724            updated 2022-08-28 13:37:21 "},"其他/排序算法.html":{"url":"其他/排序算法.html","title":"排序算法","keywords":"","body":"1. 排序1.1. 选择排序1.2. 插入排序1.3. 归并排序1.4. 快速排序1. 排序 1.1. 选择排序 交换次数最少的排序, 每次从未排序区间选择一个最小的元素.适合交换成本高的场景. 不稳定. 1.2. 插入排序 每次将一个数字插入到有序数组之中. 适合小区间排序. 1.3. 归并排序 合并两个有序数组,得到更长的有序数组. 借助了额外空间,可以实现稳定排序. 1.4. 快速排序 // 挖坑法 int partition(vector &nums, int l, int r) { int index = rand() % (r - l + 1) + l; int pivot = nums[index]; swap(nums[l], nums[index]); while (l = pivot) { r--; } nums[l] = nums[r]; while (l &nums, int l, int r) { if (l >= r) { return; } int mid = partition(nums, l, r); qSort(nums, l, mid - 1); qSort(nums, mid + 1, r); } By JNS0724            updated 2022-08-28 13:37:21 "},"分布式/DDIA/一致性与共识.html":{"url":"分布式/DDIA/一致性与共识.html","title":"一致性与共识","keywords":"","body":"1. 一致性与共识 linearizability1.1. 最终一致性1.2. 线性一致性 强一致性1.2.1. 可串行化1.2.2. 线性一致性的作用1. 一致性与共识 linearizability CAP理论中的 C 强一致性strong consistency 1.1. 最终一致性 写入数据后等待一段不确定的时间，那么所有的读取请求都会返回相同的值。 非常弱的保证，不能确保什么时候副本能够收敛 一致性和事务隔离的区别在于，分布式一致性主要关于面对延迟和故障时，如何协调副本间的状态。 1.2. 线性一致性 强一致性 常用的最强一致性模型。 使系统看起来只有一个副本，因为多副本就意味着可能有多个不一致的状态，不能保证两次读取都是新值。 系统保障了所有请求读到的值是最新的值。 解决方案就是：增加约束，让第一次读取之后的后续读取也要是新值。 1.2.1. 可串行化 可串行化（Serializability） 是事务的隔离属性，每个事务可以读写多个对象（行，文档，记录）它确保事务的行为，与它们按照某种顺序依次执行的结果相同（每个事务在下一个事务开始之前运行完成）。这种执行顺序可以与事务实际执行的顺序不同。 线性一致性（Linearizability） 是读取和写入寄存器（单个对象）的 新鲜度保证。它不会将操作组合为事务，因此它也不会阻止写入偏差等问题。 基于两阶段锁定的可串行化实现，通常是线性一致性的。但MVCC就不是线性一致性的。 一个数据库可以提供可串行化和线性一致性，这种组合被称为严格的可串行化或 强的单副本可串行化（strong-1SR） 跟可序列化不同，也就是我们不能强规定读写的顺序序列化，但保证读写的版本是最新的。 在分布式系统文献中，这个接收请求返回数据的称为寄存器。 如果读取（与写入同时发生时）可能返回旧值或新值，则称该寄存器为 常规寄存器（regular register） 1.2.2. 线性一致性的作用 分布式选主，防止脑裂。 By JNS0724            updated 2022-08-28 13:37:21 "},"分布式/基础理论.html":{"url":"分布式/基础理论.html","title":"基础理论","keywords":"","body":"1. 分布式理论1. 分布式理论 By JNS0724            updated 2022-08-28 13:37:21 "},"操作系统/ebpf/总结.html":{"url":"操作系统/ebpf/总结.html","title":"总结","keywords":"","body":"1. 一些总结1.1. tracing数据源1. 一些总结 1.1. tracing数据源 hardware events 硬件实现 tracepoint 静态 kprobe 动态 function hooks（ftrace） 动态/静态 fentry/fexit（ebpf）动态 静态探针稳定、性能好 动态探针可以hook几乎所有内核函数，不稳定，性能较差。 By JNS0724            updated 2022-08-28 13:37:21 "},"操作系统/Linux/内核/内核架构.html":{"url":"操作系统/Linux/内核/内核架构.html","title":"内核架构","keywords":"","body":"1. Linux内核1.1. 子系统1.2. 进程调度1. Linux内核 1.1. 子系统 进程调度、内存管理、虚拟文件系统、网络、ipc（进程通信） 1.2. 进程调度 By JNS0724            updated 2022-08-28 13:37:21 "},"操作系统/Linux/Linux线程.html":{"url":"操作系统/Linux/Linux线程.html","title":"Linux线程","keywords":"","body":"1. Linux 线程1.1. LWP1.2. Linux线程库1.3. 线程栈1.4. 上下文切换1.4.1. 系统调用1.4.2. 进程上下文1.4.3. 线程上下文切换1. Linux 线程 Linux本来是没有线程的，从进程演化出线程，主要是为了更好的支持SMP以及减小（进程/线程）上下文切换开销。 内核态线程更利于并发使用多处理器的资源，用户态线程考虑的是减少上下文切换的开销。 1.1. LWP Linux为支持线程，定义了LWP 轻量级进程，通过clone()系统调用来创建。 LWP：从Linux2.0开始支持，通过clone创建的进程(内部也是调用了fork)，由于LWP和父进程会共享部分资源，比如地址空间，文件系统，文件句柄，信号处理函数等，所以把LWP称为轻量级进程。 线程组：从Linux2.6开始支持，其实就是在task_struct中增加了tgid(thread group id)字段，一般认为Linux通过这种方式支持了线程，其中进程的tgid等于自己的pid，线程的tgid等于进程的pid。 1.2. Linux线程库 Linux线程库主要有LinuxThreads和NPTL（Native POSIX Thread Library），LinuxThreads逐渐被NPTL取代。LinuxThreads和NPTL都是1:1的调度模型，用户线程其实就是通过clone创建的LWP。 1.3. 线程栈 在 64 位系统中，除了主线程之外，其它线程的栈默认大小为 8M，而主线程的栈则没有这个限制，因为主线程的栈可以动态增长。可以用ulimit -s查看线程栈的大小 可以设置线程栈的大小 pthread_attr_setstacksize (&attr, size); 1.4. 上下文切换 1.4.1. 系统调用 系统调用的时候有cpu上下文的切换 首先，把 CPU 寄存器里原来用户态的指令位置保存起来 为了执行内核代码，CPU 寄存器需要更新为内核态指令的新位置，最后跳转到内核态运行内核任务。 系统调用结束后，CPU 寄存器需要恢复原来保存的用户态，然后再切换到用户空间，继续运行进程 所以，一次系统调用的过程，其实是发生了两次 CPU 上下文切换。 1.4.2. 进程上下文 上下文切换包括两部分： 进程地址空间切换： 页表切换 TLB刷新 处理器状态切换： 保存、恢复栈信息和寄存器信息 １．发生中断时的保存现场，将发生中断时的所有通用寄存器保存到进程的内核栈，使用struct pt_regs结构。 ２．地址空间切换将进程自己的页全局目录的基地址ｐgｄ保存在ttbr0_le1中，用于ｍｍｕ的页表遍历的起始点。 1.4.3. 线程上下文切换 前后两个线程属于不同进程。此时因为资源不共享，所以切换过程就跟进程上下文切换是一样的。 前后两个线程属于同一个进程。此时虚拟内存是共享的，上下文切换时，虚拟内存这些资源保持不动，只需要切换线程的私有数、寄存器等不共享的数据。 By JNS0724            updated 2022-08-28 13:37:21 "},"操作系统/Linux/中断.html":{"url":"操作系统/Linux/中断.html","title":"中断","keywords":"","body":"1. 操作系统中断1.1. 中断和异常1.2. 外中断信号1.2.1. IRQ和PIC1.2.2. 中断描述符表 IDT1.2.3. 中断和异常处理程序的嵌套执行1.2.4. Linux门描述符分类1.2.5. IDT初始化1.3. 异常处理1.3.1. 异常处理程序结构1.4. 中断处理1.5. 信号和中断1. 操作系统中断 中断通常分为同步中断和异步中断。 同步 来自cpu内部，当指令执行时由CPU控制单元产生的，只有在一条指令终止执行后CPU才能产生中断。 在Intel微处理器手册中，又称为异常，是由程序的错误或者由内核必须处理的异常条件产生的。对于第一个错误，内核通过发送一个信号来处理异常；第二种情况下，内核执行恢复异常所需的步骤，如缺页或内核服务的请求 int sysenter系统调用指令 异步 来自其他硬件设备的中断信号，分为可屏蔽和不可屏蔽 在Intel微处理器手册中，称为中断，由间隔定时器和IO设备产生，如键盘输入。 系统调用也是通过软中断实现的. 1.1. 中断和异常 中断分为： 可屏蔽中断：IO设备发出的所有中断。中断位于两种状态，屏蔽的和非屏蔽的，屏蔽时，控制单元忽略它。根据中断允许标志来判断cpu是否响应。 非屏蔽中断：危急事件，如硬件故障。 异常分为： 取决于cpu在产生异常时保存在内核态堆栈eip寄存器的值。 故障 fault：可以纠正，一旦纠正就可以不失连贯性重新开始。保存在eip的是引起故障的指令地址，当异常处理程序终止，那条指令会重新执行。 陷阱 trap：保存在eip的是随后要执行的指令地址。主要用途是调试程序。 异常中止 abort：用于报告严重的错误，硬件故障或系统表无效的值或不一样的值。 编程异常：编程者发出请求时产生，由int和int3指令触发，程序溢出或越界。通常称为软中断，用途是执行系统调用或给调试程序报告特定的事件。 每个中断和异常由0-255的数来标识，Intel称为向量。非屏蔽中断和异常的向量时固定的，可屏蔽中断的向量可以通过对中断控制器的编程来改变。 1.2. 外中断信号 当一个中断信号达到时，cpu停止当前工作，切换到新的活动。为实现这一点，要在内核态堆栈中保存程序计数器的当前值（eip和cs），并把中断类型的地址放进程序计数器。 中断处理和进程切换的差异在于中断处理执行的代码不是一个进程，是一个内核控制路径，比内核轻量。 中断处理约束： 响应中断后的操作由两部分，关键的立即执行，非关键的随后执行。 中断处理程序必须编写成使相应的内核控制路径能以嵌套的方式运行。最后一个内核控制路径终止时，能恢复被中断进程。 在内核代码临界区，中断必须被禁止。 1.2.1. IRQ和PIC 硬件设备控制器通过IRQ输出线发出中断请求，IRQ线和可编程中断控制器PIC相连。 可编程中断控制器PIC执行如下动作： 监视IRQ线，检查信号。 将信号转为向量，存放在中断控制器的IO端口，被cpu通过数据总线读取。发送信号到INTR引脚，产生中断，等到cpu确认，清INTR线。 80x86微处理器每个cpu都含有一个本地APIC，每个APIC由32位的寄存器、一个内部时钟、一个本地定时设备及为本地APIC中断保留的两条额外IRQ线。所有本地APIC连接到外部APIC，形成多APIC系统。 1.2.2. 中断描述符表 IDT 系统表，和每一个中断或异常向量相联系，每一个向量在表中都有相应的中断或异常处理程序入口地址。 IDT由IDTR寄存器来寻址。 IDT包含三种类型的描述符。 任务门 必须取代当前进程的TSS选择符存放在任务门中。 中断门 包含段选择符和中断处理程序的段内偏移量，当控制权转移到一个适当的段时，处理器清IF标志，关闭可屏蔽中断。 陷阱门 与中断门类似，但不清理IF标志。 Linux利用中断门处理中断，陷阱门处理异常。 当执行一条指令后，cpu会检查前一条指令运行时是否产生中断或异常。如果是： 确定中断或异常向量i。 读idtr寄存器指向的IDT表中的第i项。 从gdtr寄存器获得GDT基地址，在GDT中查找，以读取IDT表项的段选择符描述的段描述符。指定了中断或异常处理程序的所在段基地址。 确信中断是授权的发生源发出。比较当前特权级CPL和段描述符特权级DPL，如果CPL小于DPL，产生异常。 检查是否发生特权级变化，即CPL不等于DPL。如果是，cpu必须开始使用和新的特权级相关的栈。读Tr寄存器，访问运行进程TSS段，将新特权级相关的栈段和栈指针的正确值装载至ss和esp寄存器，在新的栈保存ss和esp以前的值。 如果故障已经产生，用引起异常的指令地址来装载cs和eip寄存器。在栈中保存eflags、sc和eip 如果异常产生了硬件出错码，保存在栈中。 7，装载cs和eip寄存器，值为IDT表中第i项门描述符的段选择符和偏移量字段。也就是跳转到中断或异常处理程序。 1.2.3. 中断和异常处理程序的嵌套执行 对于中断，内核控制路径可以任意嵌套，中断处理程序可以被另一个中断处理程序中断。但中断处理程序永不阻塞，不能切换进程。 对于异常，大多数异常发生在用户态。然而，缺页发生在内核态，缺页中断可以挂起进程，直到请求的页可用。 中断处理程序可以抢占中断处理程序，也可以抢占异常处理程序。但异常处理程序不能抢占中断处理程序。中断处理程序从不执行可以导致缺页的操作。 与异常相关的内核控制路径可以在一个cpu执行，由于进程切换转移到另一个cpu执行。 1.2.4. Linux门描述符分类 中断门 用户态进程不能访问，门DPL为0，所有Linux中断处理程序都通过中断门激活，全部限制在内核态。 系统门 用户态可以访问，门DPL为3，可以发布into bound和int $0x80 系统中断门 用户态能访问，int3。 陷阱门 用户态不能访问。Linux异常处理程序都通过陷阱门来激活。 任务门 用户态不能访问，Linux的Double Fault。 1.2.5. IDT初始化 实模式由BIOS使用，Linux接管后，二次初始化到RAM另一个区域。 1.3. 异常处理 1.3.1. 异常处理程序结构 在内核堆栈中保存大多数寄存器的内容（汇编实现） 用C函数处理异常 ret_from_exception异常处理程序 1.4. 中断处理 中断处理依赖于中断类型： IO中断 时钟中断 处理器间中断 1.5. 信号和中断 中断机制面向的是处理器，处理器在受到中断信号时，查询中断向量表，执行中断服务程序，服务完成返回中断点。中断处理是在内核态执行的。 信号机制面向的是进程，进程之间约定好收到某个信号就做什么事情。(1)当一个进程想向另一个进程发送信号，或者(2)内核收到某些硬件中断或终端中断，有必要向进程发送信号告知有某种事件产生。进程在接收到信号的情况下，根据信号的处理设置（大部分信号可定制处理程序），去执行信号处理程序。信号处理程序是在用户态执行的。本质上，信号是一种进程间通信。 信号与中断的相似之处： 都是异步的通信方式 中断执行流，执行完服务程序就返回原来的断点 信号和中断都是可屏蔽的 信号与中断的区别 中断有优先级，而信号没有优先级，所有的信号都是平等的 信号处理程序在用户态下执行，而中断服务程序在内核态下执行 中断响应是及时的，而信号响应通常有较大的时间延迟 信号的接收与处理时机 信号是异步的，一个进程不可能等待信号的到来，也不知道信号是否会到来，何时到来。因此，信号的接收不可能是进程本身完成，而是由内核代理。当进程收到一个信号，内核就在进程的未决信号集上添加该信号。这就是信号的接收时机。相对简单。但是信号的处理时机并不是在信号被接收的时候。 内核处理一个进程收到的信号的时机是在进程从内核态返回用户态时。在一个进程在内核态下运行时，信号并不立即起作用，要等到返回用户态才处理。进程只有处理完信号才会返回用户态，进程在用户态下不会有未处理完的信号。 By JNS0724            updated 2022-08-28 13:37:21 "},"操作系统/Linux/同步和通信.html":{"url":"操作系统/Linux/同步和通信.html","title":"同步和通信","keywords":"","body":"1. 并发1.1. 原子指令1.2. System V1.3. posix1.4. system v 和 posix1.5. 进程间通信1.5.1. Unix ipc1.5.2. System ipc1.5.3. Posix ipc1.6. 进程间同步1.7. 共享内存1.8. linux内核同步1.9. cas1.10. futex1. 并发 1.1. 原子指令 x86实现原子操作： 读写一个cache行是单核原子指令，关中断即可。 MESI协议，如果要访问的区域在cache上了，就可以通过缓存一致性协议来锁 锁总线 1.2. System V Unix操作系统在操作风格上主要分为System V和BSD。System V它最初由AT&T开发，曾经也被称为AT&T System V，是Unix操作系统众多版本中的一支。 1.3. posix Posix是Portable Operating System Interface(可移植性操作系统接口)的简称，是一个电气与电子工程学会即IEEE开发的一系列标准，目的是为运行在不同操作系统的应用程序提供统一的接口，实现者是不同的操作系统内核。 1.4. system v 和 posix 总结: system v就是某一个unix操作系统风格,posix是统一的操作系统接口标准,概念是位于系统之上. 1.5. 进程间通信 1.5.1. Unix ipc 管道 通过内核缓存区和循环队列实现的半双工通信 匿名管道：父子兄弟进程通信 一个内核缓冲区，只能两个进程通信，一端读一端写。写的时候在文件尾部写，读的时候在文件头部读。 写的时候，如果读不存在，将收到SIGPIPE信号，可以忽略。写满了阻塞。 读的时候，如果写不存在，认为读到数据末尾，返回数据字节数为0. 命名管道：不相关的进程也可以通信,有特定的文件名,通过命令mkfifo或者系统调用mkfifo来创建.命名管道是可以用open来打开读取的.同时也可以像普通文件一样删除. 命名管道多一个打开操作 open，必须存在读写端，不然一端会阻塞。 int mkfifo(const char *pathname, mode_t mode); //pathname文件路径，mode八进制权限 信号 用于通知接收进程某个事件已经发生,开销最小。linux除了支持Unix早期信号语义函数sigal外，还支持语义符合Posix.1标准的信号函数sigaction. 软件层面对中断机制的模拟。一个进程可以给另一个进程发送信号，唯一的异步通信手段，跟中断一样，信号也可以屏蔽。信号向量表位于内核空间，但是信号处理函数位于用户空间。 1.5.2. System ipc 消息队列 信号量 基于内核 共享内存 1.5.3. Posix ipc 消息队列 消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点 信号量 位于用户态 计数器 共享内存 共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。最快的进程间通信 1.6. 进程间同步 原子操作 原子操作与硬件架构强相关，通过汇编实现。 信号量（semaphore） 基于spinlock实现 读写信号量（rw_semaphore） 互斥锁 1.7. 共享内存 主流的方式： 传统的System V shmget 对应的文件在交换分区上的 shm 文件系统内 历史悠久。shmget()得到一个共享内存对象的id，用shmat()映射到进程自己的内存地址。这部分内存由内核管理，用户不可见。除非被一个进程明确的删除，否则它始终存在于内存里， 基于Posix mmap文件映射实现 shm_open + mmap 会在/dev/shm/下打开一个文件，用mmap映射到自己的内存地址。用户可以访问该目录。/dev/shm默认的大小为当前物理内存的1/2。 两种共享内存都由tmpfs实现，都是处于内存中的文件系统。但是是不同的tmpfs实例。 通过/proc/sys/kernel/shmmax可以限制SYS V共享内存(单个)的最大值，通过/dev/shm可以限制POSIX共享内存的最大值(所有之和)。 1.8. linux内核同步 Spinlock spin_lock用于阻止在不同CPU上的执行单元对共享资源的同时访问以及不同进程上下文互相抢占导致的对共享资源的非同步访问，而中断失效（spin_lock_irq）和软中断失效(spin_lock_bh)却是为了阻止在同一CPU上软中断或中断对共享资源的非同步访问。 Mutex 基于spinlock实现 Rwlock 1.9. cas 比较是不是期望的一致,如果是将其设置为自己想要的值. 单核通过cmpxchgq汇编指令实现,通过关中断实现原子性。 多核通过锁总线和缓存一致性协议。 1.10. futex std::mutex底层是futex实现。 futex Fast Userspace Mutexes是一个系统调用,内核态和用户态混合的同步机制.首先进程间通过mmap共享一段内存,创建一个原子计数,通过CAS来进行加减.如果有竞争,则需要进行休眠和唤醒操作.相当于在共享内存上的信号量.CAS就是操作系统的spinlock实现的. futex futex的使用是用户态先mmap得到一个地址,在这个地址上去cas修改,当有竞争时,就使用futex系统调用把这个地址传进去,并选择futex_wait.竞争消失后再通过futex_wake唤醒. 总结:futex提供了在用户态进行锁获取和内核态进行排队的方式. By JNS0724            updated 2022-08-28 13:37:21 "},"操作系统/Linux/基础概念.html":{"url":"操作系统/Linux/基础概念.html","title":"基础概念","keywords":"","body":"1. 基础概念1.1. SMP架构1.2. Numa架构1.3. MPP大规模并行处理模型1. 基础概念 1.1. SMP架构 对称多处理器结构，Symmetrical Multi-Processing。所有的CPU处理器的地位是平等的，共享所有的设备资源, 所有的资源对处理器具有相同的可访问性，如 : 磁盘,内存,总线等; 多个CPU处理器共享相同的物理内存 ,每个 CPU 访问相同的物理地址 , 所消耗的时间是相同的。 优点：避免了结构差异导致的问题，所有资源都能共享。 缺点：扩展能力有限，随着cpu数量增加，对资源的竞争导致性能下降。 Linux的SMP对称多处理器结构，负责使cpu之间共享资源。将进程在不同的cpu之间迁移。 1.2. Numa架构 非一致性处理模型，良好的扩展性 具有多个Node模块，每个Node模块由多个CPU组成，并且具有独立的本地内存。访问本地内存的速度比访问远地内存的速度要快。 1.3. MPP大规模并行处理模型 MPP(Massively Parallel Processing)提供了另外一种进行系统扩展的方式，它由多个SMP 服务器通过一定的节点互联网络进行连接，协同工作，完成相同的任务，从用户的角度来看是一个服务器系统。其基本特征是由多个 SMP 服务器 (每个 SMP 服务器称节点) 通过节点互联网络连接而成，每个节点只访问自己的本地资源 (内存、存储等) ，是一种完全无共享 (Share Nothing) 结构，因而扩展能力最好，理论上其扩展无限制。 By JNS0724            updated 2022-08-28 13:37:21 "},"操作系统/Linux/常用命令.html":{"url":"操作系统/Linux/常用命令.html","title":"常用命令","keywords":"","body":"1. 常用命令1. 常用命令 By JNS0724            updated 2022-08-28 13:37:21 "},"操作系统/Linux/虚拟内存.html":{"url":"操作系统/Linux/虚拟内存.html","title":"虚拟内存","keywords":"","body":"1. 虚拟内存1.1. 线性地址1.2. 进程内存1. 虚拟内存 1.1. 线性地址 MMU的工作原理： 64位Linux使用的是四级页表，首先在cr3寄存器得到页表全局目录基地址，在线性地址取一部分和基地址相加，得到页上级目录地址。依次类推，最后得到一个物理地址。 页表中存有有效位，如果有效位为0，说明物理页不在内存中，需要发起缺页中断。 1.2. 进程内存 进程虚拟内存布局 32位: 从低地址到高地址,内核占高地址1G,进程占低地址3G. 64位:内核占高地址128T,进程占低地址128T,中间部分未定义. 栈在运行时会用ebp和esp指针分别指向栈底和栈顶，如果我们访问一个地址是esp+32范围内的，内核就自动进行栈动态分配。 一整块区域都由mm_struct描述 这里的栈区域是主线程的栈大小 子线程的栈区域大小可有ulimit -s查看,默认是8M,是主线程clone线程时创建的,位于堆或者mmap区域. 对于heap的操作，操作系统提供了brk()函数，c运行时库提供了sbrk()函数。 对于mmap映射区域的操作，操作系统提供了mmap()和munmap()函数。 mmap映射区域有四种映射: 按权限分私有和共享,按功能分为匿名和文件映射. 1.私有文件映射 多个进程使用同样的物理内存页进行初始化，但是各个进程对内存文件的修改不会共享，也不会反应到物理文件中 通常用来加载动态库。 2.私有匿名映射 mmap会创建一个新的映射，各个进程不共享，这种使用主要用于分配内存(malloc分配大内存会调用mmap)。例如开辟新进程时，会为每个进程分配虚拟的地址空间，这些虚拟地址映射的物理内存空间各个进程间读的时候共享，写的时候会copy-on-write。 3.共享文件映射 多个进程通过虚拟内存技术共享同样的物理内存空间，对内存文件的修改会反应到实际物理文件中，也是进程间通信(IPC)的一种机制。 用于内存映射IO，进程间通信。 4.共享匿名映射 这种机制在进行fork的时候不会采用写时复制，父子进程完全共享同样的物理内存页，这也就实现了父子进程通信(IPC)。只能父子进程用。 这些系统调用一般开发者不直接使用,通过插件式的内存管理器来管理内存.比如ptmalloc tcmalloc By JNS0724            updated 2022-08-28 13:37:21 "},"操作系统/Linux/虚拟文件系统.html":{"url":"操作系统/Linux/虚拟文件系统.html","title":"虚拟文件系统","keywords":"","body":" By JNS0724            updated 2022-08-28 13:37:21 "},"操作系统/Linux/进程.html":{"url":"操作系统/Linux/进程.html","title":"进程","keywords":"","body":"1. 进程1.1. 第一个进程1.2. 进程描述符1.2.1. 获得进程描述符1.3. 进程创建1.3.1. fork1.3.2. 创建线程的时候1.3.3. exec1.4. 僵死进程和孤儿进程1.4.1. 僵尸进程1.4.2. 孤儿进程1.5. 进程和线程的区别1.6. 进程状态1.7. 进程家族1.8. 进程调度1.8.1. 进程分类1.8.2. 进程优先级1.8.3. Linux进程调度1.9. 进程上下文切换1.9.1. 进程的地址空间切换1.9.2. 寄存器状态切换1.10. 进程内存分配1.11. task_struct1. 进程 Linux系统下也成为任务（task） 1.1. 第一个进程 Linux对进程采用了一种层次系统，每个进程都依赖于一个父进程。内核启动init程序作为第一个进程，该进程负责进一步的系统初始化操作，并显示登录提示符或图形登录界面。因此init是进程树的根，所有进程都直接或间接起源自该进程。 1.2. 进程描述符 task_struct，描述进程打开的文件、地址空间、挂起的信号、进程的状态。通过slab分配器分配task_struct。 过去的task_struct存放在内核栈的尾端，为了x86寄存器少的快速计算。现在用slab分配器动态生成task_struct，只需在栈底和栈顶创建thread_info。 volatile long state; // 进程状态 pid_t pid; // 进程pid pid_t tgid; // 进程组id 主线程tgid和pid一样，其他线程不一样 struct task_struct *parent; // 父进程 struct list_head children; // 子进程链表 struct list_head sibling; // 兄弟进程链表 void *stack; // 指向内核栈的指针 // 内核栈结构 union thread_union { struct thread_info thread_info; unsigned long stack[THREAD_SIZE/sizeof(long)]; }; stack指向的时thread_info这个结构体，保存了进程描述符中中频繁访问和需要快速访问的字段，内核依赖于该数据结构来获得当前进程的描述符. 内核通过PID来标识进程，默认最大值32768，可以通过pid_max来提高上限。 1.2.1. 获得进程描述符 x86通过内核栈的栈指针计算thread_info，接着从thread_info中的task域指向获得task_struct。 内核栈是进程陷入内核态之后，运行的堆栈空间。地址从高到低，一般就8k，低地址存放着thread_info。 1.3. 进程创建 进程创建分为两步:fork()和exec(). 1.3.1. fork fork拷贝当前进程创建一个子进程,子进程和父进程的区别在于PID(进程唯一),PPID(被拷贝进程的PID)和部分资源 写时拷贝 父进程和子进程使用一个地址空间,只有当子进程要写时,才会发生数据页的拷贝.实际上就是先拷贝了个指针。 具体实现 pid_t fork(); // 该进程为父进程时，返回子进程的pid // 该进程为子进程时，返回0 // fork执行失败，返回-1 fork的实现分为以下两步 复制进程资源 执行该进程 复制进程的资源包括以下几步 进程pcb 程序体，即代码段数据段等 用户栈 内核栈 虚拟内存池 页表 步骤： 执行系统调用，陷入内核态，保存现场，调用sys_fork()、do_fork() do_fork调用copy_process创建task_struct和内核栈、thread_info，获取pid。然后复制打开的文件，复制信号处理函数，复制进程虚拟内存空间，复制命名空间。拷贝程序体和用户栈。 唤醒子进程，父子进程平分父进程剩余的时间片。加入就绪队列。 vfork() ork子进程拷贝父进程的数据段、代码段，vfork子进程与父进程共享数据段 1.3.2. 创建线程的时候 一样的步骤，clone的时候flags设置了共享地址空间、文件系统资源、文件描述符和信号处理程序。 1.3.3. exec exec负责读取可执行文件并将其载入地址空间开始运行. 使用场景：进程想要打开另一个程序。一般在fork后调用，然后exec替代子进程的代码段数据段。 1.4. 僵死进程和孤儿进程 进程终结时，会调用exit系统调用结束进程，释放空间，向父进程发送信号 1.4.1. 僵尸进程 当进程exit()退出之后，他的父进程没有通过wait()系统调用回收他的进程描述符的信息，该进程会继续停留在系统的进程表中，占用内核资源，这样的进程就是僵尸进程。 僵尸进程是不能直接使用kill -9命令杀掉的 1.4.2. 孤儿进程 如果父进程在子进程之前退出，这些子进程就会称为孤儿进程。必须要找到别的进程来作为其父进程。一般来说会被init进程收养。 孤儿进程会由init进程收养作为子进程，所以不会有什么危害；僵尸进程会占用进程号，以及未回收的文件描述符占用空间，如果产生大量的僵尸进程，将会导致系统无法分配进程号，说明父进程的代码编写有问题。 如何解决： 干掉父进程，子进程被init进程收养 父进程调用 wait 或 waitpid signal 函数，父进程收到信号后在handler后调用wait回收 1.5. 进程和线程的区别 进程拥有的资源： 有一段进程专用的系统堆栈空间和系统空间堆栈。 有进程描述符，用于描述进程的相关信息。 有独立的存储空间，也就是专有的用户空间，相应的又会有用户空间堆栈。 linux中，进程和线程唯一区别是有没有独立的地址空间。 1.6. 进程状态 TASK_RUNNING 可运行状态。未必正在使用CPU，也许是在等待调度 TASK_INTERRUPTIBLE 可中断的睡眠状态。正在等待某个条件满足 TASK_UNINTERRUPTIBLE 不可中断的睡眠状态。不会被信号中断 TASK_STOPPED 暂停状态。收到某种信号，运行被停止 TASK_TRACED 被跟踪状态。进程停止，被另一个进程跟踪 EXIT_ZOMBIE 僵尸状态。进程已经退出，但尚未被父进程或者init进程收尸 EXIT_DEAD 真正的死亡状态 1.7. 进程家族 1.init进程 所有进程都是PID为1的init进程的后代，内核在系统启动的最后阶段启动init进程。 init进程目的：读取系统的初始化脚本，并执行其他的相关程序，最终完成系统启动的整个过程。 2.task_struct中记录父子进程 parent指针（指向父进程） children子进程链表 1.8. 进程调度 https://segmentfault.com/a/1190000039367851?utm_source=sf-similar-article 1.8.1. 进程分类 IO密集型、cpu密集型 在调度器中往往需要对IO密集型进程进行奖励来提高其调度优先级，对CPU密集型进程进行惩罚降低其调度优先级。 1.8.2. 进程优先级 根据进程的重要性，可以分为： 实时进程(Real-Time Process) 普通进程(Normal Process) 实时进程PR值范围是0~99，数值越大被调度优先级越高 普通进程PR值范围是100~139，数值越小被调度优先级越高 Nice值范围是-20~19，并不是优先级但影响PR值，一般作用在普通进程上 综合来说： 实时进程要更优先被调度，普通进程的优先级一定低于实时进程 IO密集型进程要调度频繁一些，IO密集型要少分配时间片，少吃多餐 CPU密集型可以稍微惩罚，CPU密集型可以分配长一些的时间片，少餐多吃 1.8.3. Linux进程调度 全局队列 linux 2.4-2.6 采用一个全局队列runqueue作为核心数据结构，具备以下特点： 多个cpu共享全局队列，并非每个cpu有单独的队列 实时进程和普通进程混合且无序存放，寻找最合适进程需要遍历 就绪进程将被添加到队列，运行结束被删除 全局队列增删进程任务时需要加锁 进程被挂到不同CPU运行，缓存利用率低 多级反馈队列 2.6.0-2.6.22 实现了per-cpu-runqueue，每个CPU都有一个就绪进程任务队列 引入活跃数组active和过期数组expire，分别存储就绪进程和结束进程 采用全局优先级：实时进程0-99，普通进程100-139，数值越低优先级越高，更容易被调度 每个优先级对应一个链表，引入bitmap数组来记录140个链表中的活跃任务情况 sched_class 在2.6.23内核中引入scheduling class的概念，将调度器模块化，系统中可以有多种调度器，使用不同策略调度不同类型的进程： Stop调度器（内核使用）：优先级最高的调度类，可以抢占其他所有进程，不能被其他进程抢占； Deadline调度器（用户限期进程）：使用红黑树，把进程按照绝对截止期限进行排序，选择最小进程进行调度运行； RT调度器（用户实时进程）：为每个优先级维护一个队列； CFS调度器（用户普通进程）：采用完全公平调度算法，引入虚拟运行时间概念； IDLE-Task调度器（内核使用）：每个CPU都会有一个idle线程，当没有其他进程可以调度时，调度运行idle线程； 不同调度器对应不同的调度策略，分别有六种调度策略： SCHED_DEADLINE：使task选择Deadline调度器来调度运行 SCHED_RR：时间片轮转，进程用完时间片后加入优先级对应运行队列的尾部，把CPU让给同优先级的其他进程； SCHED_FIFO：先进先出调度没有时间片，没有更高优先级的情况下，只能等待主动让出CPU； SCHED_NORMAL：使task选择CFS调度器来调度运行； SCHED_BATCH：批量处理，使task选择CFS调度器来调度运行； SCHED_IDLE：使task以最低优先级选择CFS调度器来调度运行； CFS调度器：SCHED_NORMAL、SCHED_BATCH、CHED_IDLE RT调度器：SCHED_FIFO、SCHED_RR DL调度器：SCHED_DEADLINE CFS：绝对公平，引入虚拟时间vritual runtime概念，虚拟运行时间越短，优先级越高。使用红黑树来保存，优先选择虚拟运行时间最小的进程。 当一个新的进程状态转换为可运行时，需要向可运行队列中插入一个新的节点。而这个过程本质上是向红黑树中插入新节点的过程。 这会发生在两种情况下： 当进程由阻塞态被唤醒 fork()调用创建新的进程 RT调度器： 优先级区间是[1, 99], 数字越大优先级越小。为了提升效率，调度器为每个优先级都单独维护了一个任务列表 1.9. 进程上下文切换 Linux 内核用函数 context_switch 进行进程的上下文切换，进程上下文切换主要涉及到两部分：进程地址空间切换和处理器状态切换： 1.9.1. 进程的地址空间切换 将下一个进程的 pgd 虚拟地址转化为物理地址存放在 ttbr0_el1 中(这是用户空间的页表基址寄存器)，当访问用户空间地址的时候 mmu 会通过这个寄存器来做遍历页表获得物理地址。完成了这一步，也就完成了进程的地址空间切换，确切的说是进程的虚拟地址空间切换。 1.9.2. 寄存器状态切换 将下一个执行的进程的描述符加载到寄存器中。 1.10. 进程内存分配 mmap、brk系统调用 brk是将数据段(.data)的最高地址指针_edata往高地址推；mmap是在进程的虚拟地址空间中（堆和栈中间，称为文件映射区域的地方）找一块空闲的虚拟内存。 1.11. task_struct struct task_struct { volatile long state; //说明了该进程是否可以执行,还是可中断等信息 unsigned long flags; //Flage 是进程号,在调用fork()时给出 int sigpending; //进程上是否有待处理的信号 mm_segment_t addr_limit; //进程地址空间,区分内核进程与普通进程在内存存放的位置不同 //0-0xBFFFFFFF for user-thead //0-0xFFFFFFFF for kernel-thread //调度标志,表示该进程是否需要重新调度,若非0,则当从内核态返回到用户态,会发生调度 volatile long need_resched; int lock_depth; //锁深度 long nice; //进程的基本时间片 //进程的调度策略,有三种,实时进程:SCHED_FIFO,SCHED_RR, 分时进程:SCHED_OTHER unsigned long policy; struct mm_struct *mm; //进程内存管理信息 int processor; //若进程不在任何CPU上运行, cpus_runnable 的值是0，否则是1 这个值在运行队列被锁时更新 unsigned long cpus_runnable, cpus_allowed; struct list_head run_list; //指向运行队列的指针 unsigned long sleep_time; //进程的睡眠时间 //用于将系统中所有的进程连成一个双向循环链表, 其根是init_task struct task_struct *next_task, *prev_task; struct mm_struct *active_mm; struct list_head local_pages; //指向本地页面 unsigned int allocation_order, nr_local_pages; struct linux_binfmt *binfmt; //进程所运行的可执行文件的格式 int exit_code, exit_signal; int pdeath_signal; //父进程终止时向子进程发送的信号 unsigned long personality; //Linux可以运行由其他UNIX操作系统生成的符合iBCS2标准的程序 int did_exec:1; pid_t pid; //进程标识符,用来代表一个进程 pid_t pgrp; //进程组标识,表示进程所属的进程组 pid_t tty_old_pgrp; //进程控制终端所在的组标识 pid_t session; //进程的会话标识 pid_t tgid; int leader; //表示进程是否为会话主管 struct task_struct *p_opptr,*p_pptr,*p_cptr,*p_ysptr,*p_osptr; struct list_head thread_group; //线程链表 struct task_struct *pidhash_next; //用于将进程链入HASH表 struct task_struct **pidhash_pprev; wait_queue_head_t wait_chldexit; //供wait4()使用 struct completion *vfork_done; //供vfork() 使用 unsigned long rt_priority; //实时优先级，用它计算实时进程调度时的weight值 //it_real_value，it_real_incr用于REAL定时器，单位为jiffies, 系统根据it_real_value //设置定时器的第一个终止时间. 在定时器到期时，向进程发送SIGALRM信号，同时根据 //it_real_incr重置终止时间，it_prof_value，it_prof_incr用于Profile定时器，单位为jiffies。 //当进程运行时，不管在何种状态下，每个tick都使it_prof_value值减一，当减到0时，向进程发送 //信号SIGPROF，并根据it_prof_incr重置时间. //it_virt_value，it_virt_value用于Virtual定时器，单位为jiffies。当进程运行时，不管在何种 //状态下，每个tick都使it_virt_value值减一当减到0时，向进程发送信号SIGVTALRM，根据 //it_virt_incr重置初值。 unsigned long it_real_value, it_prof_value, it_virt_value; unsigned long it_real_incr, it_prof_incr, it_virt_value; struct timer_list real_timer; //指向实时定时器的指针 struct tms times; //记录进程消耗的时间 unsigned long start_time; //进程创建的时间 //记录进程在每个CPU上所消耗的用户态时间和核心态时间 long per_cpu_utime[NR_CPUS], per_cpu_stime[NR_CPUS]; //内存缺页和交换信息: //min_flt, maj_flt累计进程的次缺页数（Copy on　Write页和匿名页）和主缺页数（从映射文件或交换 //设备读入的页面数）； nswap记录进程累计换出的页面数，即写到交换设备上的页面数。 //cmin_flt, cmaj_flt, cnswap记录本进程为祖先的所有子孙进程的累计次缺页数，主缺页数和换出页面数。 //在父进程回收终止的子进程时，父进程会将子进程的这些信息累计到自己结构的这些域中 unsigned long min_flt, maj_flt, nswap, cmin_flt, cmaj_flt, cnswap; int swappable:1; //表示进程的虚拟地址空间是否允许换出 //进程认证信息 //uid,gid为运行该进程的用户的用户标识符和组标识符，通常是进程创建者的uid，gid //euid，egid为有效uid,gid //fsuid，fsgid为文件系统uid,gid，这两个ID号通常与有效uid,gid相等，在检查对于文件 //系统的访问权限时使用他们。 //suid，sgid为备份uid,gid uid_t uid,euid,suid,fsuid; gid_t gid,egid,sgid,fsgid; int ngroups; //记录进程在多少个用户组中 gid_t groups[NGROUPS]; //记录进程所在的组 //进程的权能，分别是有效位集合，继承位集合，允许位集合 kernel_cap_t cap_effective, cap_inheritable, cap_permitted; int keep_capabilities:1; struct user_struct *user; struct rlimit rlim[RLIM_NLIMITS]; //与进程相关的资源限制信息 unsigned short used_math; //是否使用FPU char comm[16]; //进程正在运行的可执行文件名 //文件系统信息 int link_count, total_link_count; //NULL if no tty 进程所在的控制终端，如果不需要控制终端，则该指针为空 struct tty_struct *tty; unsigned int locks; //进程间通信信息 struct sem_undo *semundo; //进程在信号灯上的所有undo操作 struct sem_queue *semsleeping; //当进程因为信号灯操作而挂起时，他在该队列中记录等待的操作 //进程的CPU状态，切换时，要保存到停止进程的task_struct中 struct thread_struct thread; //文件系统信息 struct fs_struct *fs; //打开文件信息 struct files_struct *files; //信号处理函数 spinlock_t sigmask_lock; struct signal_struct *sig; //信号处理函数 sigset_t blocked; //进程当前要阻塞的信号，每个信号对应一位 struct sigpending pending; //进程上是否有待处理的信号 unsigned long sas_ss_sp; size_t sas_ss_size; int (*notifier)(void *priv); void *notifier_data; sigset_t *notifier_mask; u32 parent_exec_id; u32 self_exec_id; spinlock_t alloc_lock; void *journal_info; By JNS0724            updated 2022-08-28 13:37:21 "},"操作系统/操作系统概念.html":{"url":"操作系统/操作系统概念.html","title":"操作系统概念","keywords":"","body":"1. 操作系统1.1. cpu架构1.2. 常用寄存器1.2.1. 通用寄存器1.2.2. 段寄存器1.3. 死锁1. 操作系统 1.1. cpu架构 x86 Intel的x86架构，CISC复杂指令集，优点就是性能比较强。使用桥的方式和IO设备进行连接。 MIPS ARM 精简指令集（RISC）处理器架构，其广泛地使用在许多嵌入式系统设计。优点就是低能耗。 RISC-V 1.2. 常用寄存器 通用寄存器、段寄存器、标志寄存器、指令寄存器 标志寄存器；进位、奇偶、零、补码之类的，记录了CPU执行指令过程中的一系列状态 指令寄存器EIP(x86), RIP(x64)它指向了下一条要执行的指令所存放的地址，CPU的工作其实就是不断取出它指向的指令，然后执行这条指令，同时指令寄存器继续指向下面一条指令 1.2.1. 通用寄存器 EAX 一般用作累加器 EBX 一般用作基址寄存器(Base) ECX 一般用来计数(Count) EDX 一般用作目标变址（Destinatin Index） ESP 一般用作堆栈指针(stack Pointer) EBP 一般用作基址指针(Base Pointer) ESI 一般用作源变址(Source Index) EDI 一般用作目标变址(Destinatin Index) x64架构中，上面的通用寄存器都扩展成为64位版本，变成rax rbx rcx rdx rsp rbp rsi rdi 1.2.2. 段寄存器 实模式存基地址，保护模式存段描述符。 CS 代码段寄存器：指向包含程序指令的段，在CS寄存器中RPL用于表示当前CPU的特权级(CPL)，CPL为0是最高权限(内核态使用)，CPL为3是用户态使用。 SS 栈段寄存器：指向当前程序的栈的段。 DS 数据段寄存器：指向保存着静态数据和全局数据的段(静态区)。 段寄存器里存的是段选择符，用来查找段描述符表中对应段描述符。每个cpu有全局描述符，每个进程可以有局部描述符。多数用户态的liunx程序都不使用局部描述符表，所以linux内核只定义了一个缺省的LDT供大多数进程共享。 linux段描述符里基地址都是0，相当于linux不用分段寻址，段描述符只是用来描述段的信息。 内核进程和用户进程之间切换的时候改段寄存器，用户进程之间切换的时候只是改cr3（页表基地址寄存器），并不改段寄存器。 1.3. 死锁 死锁产生的条件： 1.互斥 只能分配给一个进程 2.禁止抢占 资源不能强制从一个进程中退出 3.持有和等待：一个进程可以在等待时持有系统资源 4.循环等待：相互等待其他进程占有的资源 预防死锁必须破坏其中的一环。 By JNS0724            updated 2022-08-28 13:37:21 "},"数据库/lsm.html":{"url":"数据库/lsm.html","title":"Lsm","keywords":"","body":"1. lsm1.1. lsm-tree1.2. leveldb1.2.1. 写入数据1.2.2. 合并流程1. lsm 适合写多读少的场景。比如日志系统。 lsm-tree的核心思想是将写入推迟转换为批量写。将数据缓存在内存，通过批量的方式顺序写入磁盘。 1.1. lsm-tree lsm在内存和磁盘中分别建立数据结构，内存中是AVL或红黑树这种有序结构，磁盘是B-tree这类适应磁盘io的数据结构。 内存memtable =》 磁盘SSTable 1.2. leveldb 内存： memtable => immutable mmtable 磁盘： level 0 : sstable sstable level 1 : sstable sstable level 2 : sstable sstable memtable：存储在内存中的数据，使用skiplist实现。 immutable memtable：与memtable一样，准备落盘的数据 多层sstable：leveldb使用多个层次来存储sstable文件，这些文件分布在磁盘上，这些文件都是根据键值有序排列的，其中0级的sstable的键值可能会重叠，而level 1及以上的sstable文件不会重叠。 越靠上的数据越新，即同一个键值如果同时存在于memtable和immutable memtable中，则以memtable中的为准。 1.2.1. 写入数据 1.append记录到log文件。追加写磁盘，写入快。 2.将数据写入memtable，如果遇到合并的时候，可能会阻塞。 3.删除数据只做删除标记。 1.2.2. 合并流程 合并是从memtable到sstable的过程。 By JNS0724            updated 2022-08-28 13:37:21 "},"数据库/mysql.html":{"url":"数据库/mysql.html","title":"Mysql","keywords":"","body":"1. 数据库1.1. mysql关键字相关1.2. MYSQL的存储引擎1.3. 数据库事务1.3.1. 事务的定义：让数据库从一个一致性状态转换为另一个一致性状态1.3.2. 事务的四大特性：4由锁实现，123由undo、redo日志实现1.3.3. 实现1.3.4. 控制语句1.4. 数据库三大范式1.5. 脏读、幻读、不可重复读与事务隔离级别1.6. 数据库的锁1.7. MYSQL索引类型与慢查询优化1.7.1. 为什么b+树要求把真实的数据放到叶子节点而不是内层节点1.7.2. 索引的最左匹配：针对于联合索引的情况1.7.3. 非聚集索引回表问题【也称为覆盖索引】1.7.4. 非聚集索引上进行update时的加锁情况：【参考：https://blog.51cto.com/u_15155077/2716366】1.7.5. 分组查询时的索引优化【参考：MySQL查询优化：GROUP BY 文章作者是：Resemble_】1.8. innoDB存储引擎的优化1.9. MVCC多版本并发控制1.10. MYSQL的执行计划1.11. MYSQL主从复制1.12. 如何处理MYSQL的慢查询1.13. 索引设计的原则1.14. 建表原则1.15. 分库分表问题1.16. 索引失效问题1.17. SQL优化1.18. mvcc1. 数据库 1.1. mysql关键字相关 1）limit和order by【参考：MYSQL排序的艺术：你真的懂Order By吗？】注意总结！！ 2）join【参考：Mysql - JOIN详解 segmentfault】 注意，join连接查询时，连接条件用on，查询条件才用where 3）union多表联合，比较简单，主要考虑其使用的前提：1、必须由两条或多条select语句组成，并在select语句之间用union。【union All 可以重复合并】2、union中每个select必须包含相同的列、表达式或聚合函数，列的数据类型必须兼容；3、多表查询的union并不要求两个表完全相同，只需要select的字段类型相同即可。 1.2. MYSQL的存储引擎 ​1、InnoDB：mysql的默认存储引擎，支持事务、支持行锁、支持外键，默认事务隔离级别是“可重复读RR”。采用MVCC机制（一致性非锁定读）支持高并发，采用next-key-lock算法防止幻读。满足数据库四个标准的隔离级别。 ​2、MyISAM：mysql5.1版本前的默认存储引擎，不支持事务和外键，默认为表级锁 区别：innoDB支持事务、行锁、外键。 1.3. 数据库事务 1.3.1. 事务的定义：让数据库从一个一致性状态转换为另一个一致性状态 1.3.2. 事务的四大特性：4由锁实现，123由undo、redo日志实现 1、原子性：要么执行，要么都不执行【undoLog，回滚日志文件】 2、一致性：事务从一个一致性状态到另一个一致性状态，完整性约束不被破坏【由其他三个特性来保证】 3、持久性：事务对数据库的更改是持久的【redoLog，重做日志】 4、隔离性：不同事务之间不会互相干扰【锁与MVCC机制】 1.3.3. 实现 ​1、redo重做日志【用于持久化】 ：innoDB存储引擎中，redo日志的持久化需要经过redo buff --> redo file的过程。事务执行时写入buf，事务提交时写入file。也不一定，innoDB没秒都有刷buff的操作【redo日志记录的是执行过的指令？？不是，记录的是物理数据页的修改信息】 2、undo撤回日志【用于回滚】：undo存放在undo段中，位于共享表空间。回滚过程不是对数据库数据的物理修改，而是执行与事务相反的操作实现逻辑回滚。 innoDB利用redo日志和undo日志实现事务。在执行事务的sql语句时，先写undo log，再写redo log，等事务的所有sql执行完后，将redo log的内容持久化到磁盘，然后事务才commit。【相当于，在执行事务的时候，写回滚日志，写重做日志缓存。且等到所有sql执行完后，先将重写日志缓存持久化到磁盘，才commit事务。】 1.3.4. 控制语句 start transaction / begin 开始事务， commit结束事务， rollback回滚事务 Savepoint identifier：创建保存点， release savepoint identifier：删除保存点 Rollback to savepoint identifier：回滚到保存点， set transaction：设置事务隔离级别 1.4. 数据库三大范式 ​ 1、第一范式：字段不可再分 ​ 2、第二范式：必须有主键，非主键字段依赖主键 ​ 3、第三范式：非主键字段不能相互依赖 1.5. 脏读、幻读、不可重复读与事务隔离级别 ​ 1、读未提交（read uncommitted）---脏读【读到了其他事务未提交的数据】 ​ 2、读可提交（read commit）：---不可重复读【读到其他事务已提交的数据】---幻读【两次读的行数不一致】 ​ *3、可重复读（repeatable read）： ​ 4、串行化（serializable） 对于快照读，MYSQL通过MVCC的多版本机制来解决RR级别下的不可重复读问题和幻读问题，以及RC级别下的脏读问题；对于加锁读，行锁就能完美解决不可重复读和脏读，而MYSQL利用Next-Key Lock（行锁+间隙锁）机制，解决RR级别下的幻读问题。 ​ MYSQL的innoDB存储引擎的默认事务隔离级别是“可重复读”。对于快照读，通过MVCC机制，在本事务开始时创建快照，本事务只对这个快照进行读，因此其他事务的修改不会影响这个快照【其他事务的修改包括：update和insert，但是由于MVCC有版本号机制，因此其他事务的这些修改，都不会被当前事务的这个快照所感知】，以此来解决“不可重复读”和幻读问题；另外，对于加锁读，采用Next-Key Lock（这种锁就是行锁+间隙锁）解决“幻读”问题。【也就是说，一致性读的情况使用MVCC机制避免这两个问题，加锁读的情况使用行锁避免不可重复读，使用间隙锁避免幻读！！！！！】【参考：https://zhuanlan.zhihu.com/p/103580034】 不可重复读和幻读的区别，关键在于行锁的理解：删除和修改某一行是，那一行都可以持有锁，但是新增数据因为原先不存在，因此无法对原先不存在的那行提前加锁。【注意不可重复读和幻读是同一层次的隔离问题】 幻读：事务A 按照一定条件进行数据读取， 期间事务B 插入了相同搜索条件的新数据【插入了原先不存在的数据】，事务A再次按照原先条件进行读取时，发现了事务B 新插入的数据。【MYSQL的解决方案：事务A读时，通过Next-Key Lock 锁住查询条件筛选出来的行，以及行之间的间隙。在事务B插入的时候，若插入的行位于被事务A的Next-Key Lock锁住的范围内时，导致阻塞。】 不可重复读：如果事务A 按一定条件搜索， 期间事务B 删除了符合条件的某一条数据【修改或删除了原先以存在的数据】，导致事务A 再次读取时数据与原先不一致。【...现在看来这实际上也是幻读的一种，】 【幻读是指一个事物的两次查询，第二次查询读到了别的事物的新增数据。RC隔离级别的加锁读，只会对存在的数据使用行锁，对于不存在的数据不会使用间隙锁，因此别的事物可以插入数据。又因为RC级别的一致性读取每次都读最新的快照，所以能读到新插入的数据，造成幻读。mysql RR隔离级别不存在幻读问题，在RR隔离级别下，一致性读使用的是第一次读取数据建立的快照数据，对于别的事物提交的数据是无感知的。若果使用加锁读，Mysql会使用间隙锁对不满足条件且不存在的数据加锁，导致别的事物无法插入符合这个条件的新数据，因此也就不会产生幻读。】 加锁读和快照读的出现场景：参考： 51cto.com/article/700127.html 下面的场景仅对RR级别存在讨论意义， ​case1和case2：因为事务A在事务Bupdate之前先select了，【相当于事务A先创建了快照，】所以导致事务A的所有select都是快照读 ​case3和case4：因为事务A在第一次select之前，事务B先update了，【相当于事务B先加了锁，】导致事务A对该行数据的读都升级为加锁读 https://blog.csdn.net/thekenofDIS/article/details/80736401?spm=1001.2101.3001.6650.2&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-2.pc_relevant_paycolumn_v3&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7EBlogCommendFromBaidu%7ERate-2.pc_relevant_paycolumn_v3&utm_relevant_index=5 普通的select操作，就是快照读，底层实现是通过读取快照实现的，因此其他事务的update等加锁操作不影响快照读 而select for update 是加锁读，其他事务的update等加锁操作会影响这个事务的加锁读。 总结： RR级别下，结合MVCC行多版本机制，仅对普通select操作能有效提高读写并发效率【这个效率提高体现在，事务A对行10进行快照读，而事务B对行10进行写，这两个事务不会因此而阻塞。】，但是对于加锁select的读写并发，以及update、delete等DML操作的写写并发并没有提高效率。 因此，mysql数据库实际上是快照读写并发，其余情况：加锁读写、写写，都是会阻塞的，不管什么事务隔离级别下。 【事务隔离级别、MVCC机制的效果都是为了提高普通select的并发性能】 RC级别下，由于RC本来就不是一致性的，存在不可重复读的问题，因此MVCC并不能提高RC级别下的普通select的读写并发。 因此，有RR级别+MVCC就能实现一致性非锁定读；而RC级别+MVCC没有效果，因为RC本来就不是一致性的。 例子1：select for update 的写写互斥【这里的加锁读可以替换成所有的加锁操作，本质上这些过程都不执行MVCC机制】 ​1）事务A开启事务；事务A select for update；事务B开启事务；事务B select for update(阻塞，因为事务A已经对那一行加了写锁) ​2）继续上面的1），事务A commit，此时会唤醒事务B的加锁读继续进行【因为事务A commit后，释放了那一行的写锁】。然后，事务A 开启新事务，事务A select for update(阻塞，因为事务B的加锁读还未commit)； ​3）继续上面的2），事务B commit，则唤醒事务A的加锁读继续进行。 例子2：select lock in share mode的读读并发、读写互斥。 ​1）事务A开启事务；事务A select lock in share mode ； 事务B开启事务；事务B select lock in share mode；两个都正常进行。【读读并发】 ​2）在1）的基础上，事务B select for update（阻塞，因为事务A上了读锁，此时会阻塞事务B的写锁）；【读写互斥】 ​3）在2）的基础上，事务A commit， 会唤醒事务B的加锁读。 1.6. 数据库的锁 1、共享锁：读锁，相互不阻塞【指令：lock in share mode】 2、排他锁：写锁，会阻塞其他的写锁和读锁【指令：for update】 意向锁：参考https://www.zhihu.com/question/51513268/answer/937543668，意向锁是在存在行锁场景下的表锁快速失败机制。 想对行加锁，就要先对表加上同样的意向锁。而意向锁之间不互斥，意向锁只跟表级锁互斥。 因此，例如：事务A对第5行加X锁，同时会对表加IX锁。而事务B对第6行加X锁，虽然同时会对表加IX锁，但是因为意向锁之间不互斥，因此没有问题。 但是如果事务B对这个表加X锁，由于意向锁和表级锁互斥，这里是写写互斥，即事务B看到事务A对这个表加了IX锁，因此事务B会阻塞，直到事务A释放这个表的IX锁。也就是：意向锁是在存在行锁场景下的表锁快速失败机制。【相当于 省了事务B加表锁时，遍历一遍是否存在其他事务加了某个行锁 的操作】 读写互斥的同理，关键是意向锁之间不互斥，意向锁跟表级锁互斥。 3、表锁、行锁、间隙锁：MYSQL中按粒度的锁分类，表锁锁住整张表，实现简单、加锁快，但并发程度低；行锁锁住某一行，若表有索引则锁住索引，没有索引则创建隐藏的聚簇索引并加锁。行锁粒度小，并发程度高，加锁慢，会出现死锁；间隙锁锁住一个范围，不包含记录本身，用于防止同一事务的两次读出现幻读现象。【Next-Key-Lock算法：行锁+间隙锁】 【innoDB对 更新操作 默认使用表锁，若更新操作使用了索引，则使用行锁】真还是假。。。【参考下面6.4的分析，无索引update时，加表锁；非聚集索引update时，根据回表情况分别 对非聚集索引行 、主键行 加各自的锁；主键update时，只加一个行锁。】 间隙锁参考：https://tech.meituan.com/2014/08/20/innodb-lock.html innoDB实现了读锁、写锁两种机制的行级锁、间隙锁。同时，innoDB支持多粒度的锁定，即意向锁。 数据库锁机制默认是悲观锁，下面的乐观、悲观和数据库无关，只是介绍锁的互斥实现。【也不是完全无关，MVCC机制可以说是使用了乐观锁思想----因为MVCC的多版本控制涉及事务的version号。】 乐观锁：数据操作时不加锁，数据提交时验证是否冲突【需要我们自己实现，在修改前，先查询version，相同则version+1继续执行，不相同则rollback】【CAS是原子操作？？是的】【innoDB讨论乐观锁没有意义，因为innoDB的MVCC机制默认就是通过version隐藏字段来实现非锁定一致性读，而这种非锁定就是乐观锁的体现------好像也不是。。。MVCC的非锁定是通过维护多个快照实现的。。】 悲观锁：修改数据前就把数据锁住，然后才进行读写，释放锁之前任何人不能操作数据。【数据库锁机制默认是悲观锁，使用时在sql语句添加相应指令（1/2中的指令）】 另外： 对于读操作，innoDB默认使用非锁定一致性读，即，除非在事务中手动加上了lock in share mode 或 for update，否则，默认的读操作都是非锁定一致性读。 ​ 非锁定一致性读是通过MVCC机制保持多个快照来实现的。对于Read Committed隔离级别，这个级别下的快照是修改后的最新快照，这个快照会被其他事务改变，因此其实并不满足事务的隔离性。而对于innoDB的默认隔离级别 Repeatable Read，不会读到其他事务的提交结果，因此这个快照是事务开始时的快照，因此，innoDB默认情况【快照读】下，事务之间的交替读写不会上锁【与直接加锁的区别在于这里：在事务执行过程中的直接加写锁，会阻塞另一个读的事务，而非锁定一致性读机制会使另一个读的事务转而去读另一个快照】，也不会有事务隔离的问题，而这是通过每次事务开始时弄一个快照，然后事务读取自己快照的信息来实现的。 ​ 但innoDB也不是一直默认使用非锁定一致性读。事务中对外键的插入和更新就是默认使用X锁、S锁，这是为了防止父子表的不一致性。 Record Lock（行） 、 Gap Lock（间隙） 、 Next-Key-Lock（行+间隙）三种 innoDB中，对于范围查询，是使用next-key锁（对查询范围加S锁），因此其他事务对查询范围内进行更新操作（加X锁）会被阻塞。 对于单值查询，使用行锁。 innoDB不会回滚大部分的错误异常，但是死锁除外。【所以这里其实是一种错误行为。参考innoDB技术内幕226页】 1.7. MYSQL索引类型与慢查询优化 参考：https://tech.meituan.com/2014/06/30/mysql-index.html 1.7.1. 为什么b+树要求把真实的数据放到叶子节点而不是内层节点 一旦放到内层节点，磁盘块的数据项会大幅度下降，导致树增高。当数据项等于1时将会退化成线性表。【因为数据行占很多空间】【不适用B树的原因】相对于Hash索引，B+树支持范围查找和排序操作 1.7.2. 索引的最左匹配：针对于联合索引的情况 考虑因素：索引定义顺序、查询条件的截断位置、mysql的索引位置优化 首先，mysql会对能满足最左匹配条件的多个查询条件进行位置的优化，比如组合索引定义为(a,b,c)，查询条件为a=1 and c=2 and b=3，则能直接调整位置使得满足最左匹配。 另外，mysql会一直向右匹配，直到遇到范围查询（>、10 and d=3，组合索引定义为（a,b,c,d）的话，d无法使用索引【要从B+树底层思考，因为索引定义顺序是abcd，因此B+树的叶子节点内容也是按照abcd来组建查询条件的，即，先查完a，才能查b。而这里索引定义为abcd，查询条件到c时就停止了，因此d索引无法使用，因为被c的范围查询阻断了。】；而如果组合索引定义为（a,b,d,c）则d的索引能使用【因为B+树的叶子按照abdc来组建，就算查询条件到c处被阻断了，也不影响B+树的“下一个索引的选择”。】【其实也可以理解为，mysql的位置优化会将查询条件按照索引定义的顺序来排。】 1.7.3. 非聚集索引回表问题【也称为覆盖索引】 ​由于非聚集索引的叶子节点存储的是【非聚集索引键，数据行的主键】，因此，如果这次select语句查的东西包含在非聚集索引叶子节点中，则不需要回表查聚集索引。 ​例如定义了非聚集索引：key1，key2 ​ 1、若select key1,key2,key3 from table where key1 = 'aaa'，由于查找内容有key3，另外，key2这个索引是单独的，因此key2、key3的列需要从主表查，因此要回表。- ​ 2、若select id, key1 from table where key1 = 'aaa'， 由于key1的叶子节点包含了id【主键】以及key1【本次非聚集索引键】，因此直接叶子节点就是要查找的内容，不需要回表。 ​ 若定义联合索引：(key1, key2) ​3、则select key1, key2, key3 from table where key1 = 'aaa'， **仅因为**key3的存在，所以要回表。【注意这里**1的单个非聚集索引**、和**3的联合索引**的区别。区别在于：（1）中key2也要回表；（2）中key2不用回表】 1.7.4. 非聚集索引上进行update时的加锁情况：【参考：https://blog.51cto.com/u_15155077/2716366】 结论：当使用非聚集索引列进行数据更新时，MySQL会使用非聚集索引进行查找，对于查找到满足过滤条件的每一行索引记录： ​1、在查找到的非聚集索引记录上加锁。【加第一种锁--非聚集索引的行锁】 ​2、根据非聚集索引记录上包含的聚集索引键值进行回表查找。【回表查询】 ​3、在查找到的聚集索引记录上加锁。【加第二种锁--主键的行锁】 ​4、循环1、2、3步处理下一条满足过滤条件的数据。 1.7.5. 分组查询时的索引优化【参考：MySQL查询优化：GROUP BY 文章作者是：Resemble_】 ​首先，分组查询的底层实现中，分为查找+排序，即查出所有分组字段，然后对分组的字段进行排序【注意与order by区别。groud by是对分组的字段排序，order by是对分组的内容排序】，之后再利用聚集函数对分组内的行进行操作。这里的索引优化的优化点在于：避免由于查找所有分组字段所需的全表扫描过程。例如，索引是B+树存储的，已经按照索引键进行排序，因此，如果需要查找某个分组字段的所有行，只需要找到【前一个分组 -- 当前分组 -- 后一个分组】的时候，就相当于找到了这个分组的所有行数据。 ​因此，这里如果select语句能把找到【前一个分组 -- 当前分组 -- 后一个分组】的时候，就相当于找到了这个分组的所有行数据的这个过程优化出来，就能在查找的过程中过滤很多的查找操作。同时，排序也避免了【因为索引自带排序属性】。 ​因此，索引对分组查询的优化，体现在三个点上： 有索引时，确定分组总数不需要全表扫描，只需要遍历分组的所有行 --- 紧凑索引【出现在，比如（c1,c2,c3）是联合索引，然后select c3 where c2 = const groud by c1,c3时，由于c2的gap打断了联合索引数据行的排序性，因此退化为紧凑索引，此时需要遍历分组的所有行】 groud by 条件符合联合索引的最左匹配时，进行聚集函数（MAX,MIN）的操作只需要遍历每个分组的第一行 --- 松散索引【例如，(c1,c2,c3)是联合索引，然后select c2, MAX(c2) from table groud by c1, c2，因此此时groud by的条件满足联合索引的最左匹配，因此查找出来的分组信息是具有排序性质的，因此求max和min可以直接通过访问第一、最后一个元素来实现，避免了遍历分组内的所有行这个过程。】 索引构造的B+树自带排序属性，因此不需要对groud by 进行分组的排序 ​但是关于松散索引、紧凑索引的触发条件，还没弄太清楚 6）分页查询的索引优化（limit关键字） ​首先，分页查询的底层原理是：limit m n 先读取前面m+n条记录，然后抛弃前m条，读取后面n条想要的记录。因此，limit越大，偏移量越大，读取的记录就越多，效率越低。 ​优化思路： ​ 1、利用索引进行子查询，避免回表操作：select * from table where id >= (select id from table LIMIT 1000000, 1) LIMIT 10。【分析：子查询中，虽然limit还是很大，但是由于是顺序查找，查询id使用了主键，且不需要回表，因此速度快上加快；】 ​ 2、利用join ​ 1、自增列、外键列自动加索引 1、数据结构角度： ​ B+索引、hash索引 2、物理存储角度： ​ 聚集索引clustered Index（主键索引）：叶子节点存储行数据 ​ 非聚集索引（辅助索引）：叶子节点存储的是【行的辅助索引值，聚集索引【主键】】2个，【因此，辅助索引的查找，先通过查辅助索引的B+树，在叶节点中给出该索引对应的主键，再通过主键查聚集索引B+树找出主键对应的数据行】 ​ innoDB是索引组织表，也就是说一张表只能有一个聚集索引。定义表结构的时候，主键就是聚集索引，如果没有主键就innoDB自动生成6字节的id。而普通的索引，比如key、foreignKey都是非聚集索引。 3、业务类型： ​ 联合索引：多个列共同定义为一个索引。例如key(a,b,c)，整个是一个联合索引。 ​ 覆盖索引：覆盖索引不是一种索引，只是一种叫法，针对于联合索引不需要回表时的查询优化。 1.8. innoDB存储引擎的优化 参考：https://www.jianshu.com/p/8f877191eedc ​ 1）插入缓冲【插入效率优化】 将对非聚集索引的插入缓冲在内存，隔段时间先合并，再一起插入。【因为非聚集索引的插入，在磁盘中是随机写【因为innoDB是索引组织表，按主键的顺序存储数据行，而非聚集索引没有顺序，因此需要随机写】，因此一个一个地写效率不高。通过插入缓冲，可以将插入同一个页的多个插入操作一起处理，这样减少了随机写磁盘的时间。】 ​ 条件：非聚集索引，且索引不唯一【如果索引是唯一的，则innoDB为了维护唯一性，在每次插入的时候都要遍历一下全表验证是否唯一，这样本来想避免的全表离散读取就无法避免了】【索引打上unique才是唯一，默认是不唯一的】 ​ 2）两次写机制【一致性优化】 ​ 问题原因在于：数据库数据页16K，文件系统数据页4k，所以将一个数据库的脏页写入文件系统需要四次IO，如果执行到第二次IO的时候数据库宕机，这时候磁盘的这16k的数据页是不完整的，且无法恢复。【文件系统一个页4k，恢复操作只能针对一个页来进行】 ​ 【这里的无法恢复，是指文件系统的一个页中存在错误数据，是一种物理意义上的错误。而不是指无法通过redo日志来恢复。】 ​ 两次写方案：正常思路：1、先将16k的数据页写到共享表空间，2、然后再将16k的数据页写入磁盘。【这样就算数据库宕机，也能从共享表空间获取最近的一份备份数据来实现恢复】 ​ 实际方案：1、先将脏页写入内存中2MB大的double write buffer；2、double write buffer将脏页写入共享表空间的double write文件；3、double write buffer再将脏页写入磁盘。【相当于不是按照一个数据页来写，而是先整合成2MB，然后再一起写入磁盘】 ​ 3）自适应哈希【热点数据回表避免】 ​ 问题原因：在B+树中通过非聚集索引查找到聚集索引后，还需要回表查行数据。 ​ 优化方案：innoDB监控热点数据，然后自适应地对热点数据建立哈希，避免多次IO回表查找真实行数据。 1.9. MVCC多版本并发控制 ​ 1）概念解释：在MYSQL的innoDB引擎中，MVCC机制能实现不加锁时的读写冲突中的并发控制，即一致性非锁定读。 ​ 2）适用场景：但是MVCC的一致性非锁定读只能在不加锁的select操作【称为快照读】中使用，对于select lock in share mode（共享锁）、select for update、update、insert、delete(排它锁)的情况，使用的是当前读，不使用MVCC机制。【即，只要当事务A仅使用快照读【整个事务只有select ！！！没有其他任何的语句！！时】，那么其他事务怎么搞，都不影响事务A的效率；但是如果事务A是使用加锁读、或者update、insert、delete，都会取消MVCC机制，转而使用加锁的机制】 ​ 3）实现方式：实现方式与事务隔离级别有关，1）在innoDB的读可提交情况下，读取被锁定行的最新一份快照数据，该机制是通过数据行记录中的三个隐藏字段当中的上一个修改指针来跟踪。2）在可重复读的情况下，读取的是事务开始时的快照。【InnoDB默认是这个】 1.10. MYSQL的执行计划 ​ explain，但是具体的现实内容，要注意整理 id：表示select查询的序列或 操作表的顺序。id相同，执行顺序从上到下，id不同，值越大越先执行 type：表示连接类型：NULL、system、const【主键索引、唯一索引时】、eq_ref、ref【非聚集索引时】、range、index【使用了索引，但还是全索引扫描，类似于groud by的索引优化那里】、all possible key ：表示该表上可能用到的索引 key：实际用到的索引 extra：1）using index condition：表示回表查询；2）using where， using index ：表示没有覆盖索引 1.11. MYSQL主从复制 ​ 1）master数据库将数据的变化记录在binLog中 ​ 2）slave数据库定时探测master的binLog，发送变化时，请求同步。接受到的数据保存到relayLog中。 1.12. 如何处理MYSQL的慢查询 1.13. 索引设计的原则 1、常用于where、order by 、groud by 操作的字段建立索引 2、为区分度高的列建立索引，区分度越高，索引效率越高【比如性别的区分度就很低】 3、字符串类型的字段过长，建立前缀索引 4、联合索引，尽量实现覆盖索引 1.14. 建表原则 ​ 1）一对一：共用主键 ​ 2）一对多：多的一方用字段关联另一边的主键【即，多的一方用冗余字段来在逻辑上代表少的一方的主键】 ​ 3）多对多：创建中间表，维护双方的主键对应关系 1.15. 分库分表问题 1）水平分表：因为表的行数过多，所以水平切一刀。按照主键id取模 2）垂直分表：因为表的列过多，所以垂直切一刀，将字段按照业务拆开。 1.16. 索引失效问题 1、最左前缀匹配：按照联合索引的顺序来最左前缀匹配，跳过了中间的字段会导致索引部分失效 2、范围查询：范围查询会导致后续的索引失效【但是，大于等于就没问题。为什么？？】 3、对索引字段进行函数运算会导致索引失效【例如字符串截取函数】 4、模糊查询：仅仅是尾部模糊匹配，索引会生效；头部模糊匹配会导致索引失效 5、or查询：其中一个查询条件的字段没有索引，会导致整个查询都不走索引 1.17. SQL优化 1、插入数据：1）批量插入；2）手动提交事务；3）按主键顺序插入 2、order by： using filesort：表示需要在排序缓冲区中进行排序，无法通过索引直接获取排序结果 using index：表示通过有序索引顺序扫描直接返回了有序数据 1.18. mvcc RC隔离级别和RR隔离级别时通过readview实现的，readview就是在某一时刻，将事务系统进行快照，记录当前活跃事务数组。之后的读操作通过事务id的状态比较，来确定readview的可见性。 By JNS0724            updated 2022-08-28 13:37:21 "},"数据库/mysql事务恢复.html":{"url":"数据库/mysql事务恢复.html","title":"mysql事务恢复","keywords":"","body":"1. mysql事务恢复1. mysql事务恢复 主要通过redolog和checkpoint来完成。 恢复过程：读取redolog文件，通过checkpoint恢复线程，checkpoint记录这次检查点的活跃事务的列表和脏页列表。undolog的记录也会记录redolog，通过记录来回滚未完成事务。 By JNS0724            updated 2022-08-28 13:37:21 "},"数据库/mysql日志.html":{"url":"数据库/mysql日志.html","title":"mysql日志","keywords":"","body":"1. mysql三个日志1.1. 前言1.2. Redo log1.2.1. Redo log buffer1.2.2. Mini-Transaction1.2.3. Redo流程1.2.4. WAL Write-Ahead Log1.2.5. redolog 刷盘时机1.3. Undo log1.3.1. Undo log的写入时机1.3.2. Undo的类型1.3.3. 回滚段1.3.4. UndoPage1.4. binlog1.5. 刷盘策略1.5.1. redolog 和 binlog1.6. 两阶段提交1.7. 崩溃恢复1. mysql三个日志 1.1. 前言 事务是数据库规定的，由应用程序与其交互的、或者说数据库对数据修改的工作单元。它的粒度是一组sql语句组成的，即使是一条sql语句，也可以构成一个微小的事务。由于事务是由多条sql语句构成，就可能涉及一张表或多张表，落到存储层面，通常是多个数据页。 为了加快数据库的数据操作过程，数据库由buffer pool来加载数据页，在执行sql语句时，通常在buffer pool上进行更新，再定时刷新脏页。 以上这些属性，导致了数据库的崩溃之后，需要有一个恢复机制，主要由Redo log和Undo log来实现。 Redo log恢复已提交事务的数据，Undo log回滚未提交事务的状态。 1.2. Redo log 重做日志主要用于在数据库崩溃后对所有已提交的事务进行数据恢复。为WAL机制设计的。 innodb充分利用缓存机制，Redo log有内存和磁盘两个区域，在内存上使用Redo log buffer来表示，在磁盘上由两个名为ib_logfile0和ib_logfile1的文件物理表示。MySQL以循环方式写入重做日志文件。 1.2.1. Redo log buffer Log Buffer内存空间的大小由启动参数innodb_log_buffer_size来指定，默认是16MB，这片内存空间被划分成若干个连续的redo log block,这也是Log Buffer的内存结构。 log buffer本质上是由若干个512字节大小的block组成的一片连续的内存空间。redo log落盘也是以block为单位写到日志组文件中去的。 其中type表示Redo log的日志类型，Innodb引擎针对不同场景对数据页的修改，制定了几十种不同类型的Redo日志。Space ID和Page Number是前边我们反复提到的表空间id和数据页id，根据它们能唯一标示一个数据页，再然后的data就是对该数据页到底做了哪些修改了。 物理日志混合逻辑日志，物理为具体某个页，逻辑为页内的修改。 1.2.2. Mini-Transaction Innodb引擎对底层页的一次原子访问的过程叫做Mini-Transaction，例如更改了插入数据页后，需要同时在B+辅助索引树中插入索引信息，对于一个Mini-Transactoin产生的redo log日志都会被划分到一个组当中去，在进行系统崩溃重启恢复时，针对某个组中的redo日志，要么把全部的日志都恢复掉，要么就一条也不恢复。 每条sql语句由多个Mini-Transaction组成。 1.2.3. Redo流程 1.2.4. WAL Write-Ahead Log 预写日志机制，当事务提交时，先将 redo log buffer 写入到 redo log file 进行持久化，待事务的commit操作完成时才算完成。至于change buffer的数据，则定时刷新。如果宕机了，则靠redo log来恢复。 1.2.5. redolog 刷盘时机 redolog刷盘需要有两个动作，写缓冲区，刷新缓冲区。 innodb_flush_log_at_trx_commit设置 策略一：性能最高，每隔一秒，redolog buffer批量写入oscache缓冲区，同时主动fsync，数据库崩溃最多丢失一秒数据。 策略二：强一致性，每次提交都主动fsync。 （常用）策略三：每次提交都写入oscache缓冲区，每隔一秒，主动批量fsync。操作系统崩溃最多丢失一秒数据。 1.3. Undo log 作用：用于实现MVCC乐观锁机制、回滚没有commit的事务。 原理： 记录和sql语句反向操作的语句，在事务回滚时，执行这些操作就可以实现事务回滚。 通过读取undo log日志，读取历史版本的数据，就是快照读。 undo log是采用分段(segment)的方式进行存储的。rollback segment称为回滚段，每个回滚段中有1024个undo log segment。在MySQL5.5之前，只支持1个rollback segment，也就是只能记录1024个undo操作。在MySQL5.5之后，可以支持128个rollback segment，分别从resg slot0 - resg slot127，每一个resg slot，也就是每一个回滚段，内部由1024个undo segment 组成，即总共可以记录128 * 1024个undo操作。 在更新数据之前，MySQL会提前生成undo log日志，当事务提交的时候，并不会立即删除undo log，因为后面可能需要进行回滚操作，要执行回滚（rollback）操作时，从缓存中读取数据。undo log日志的删除是通过通过后台purge线程进行回收处理的。 1.3.1. Undo log的写入时机 DML操作修改聚簇索引前，记录undo日志 二级索引记录的修改，不记录undo日志 需要注意的是，undo页面的修改，同样需要记录redo日志。 1.3.2. Undo的类型 insert undo log update undo log insert undo log是指在insert 操作中产生的undo log，因为insert操作的记录，只对事务本身可见，对其他事务不可见。故该undo log可以在事务提交后直接删除，不需要进行purge操作。 而update undo log记录的是对delete 和update操作产生的undo log，该undo log可能需要提供MVCC机制，因此不能再事务提交时就进行删除。提交时放入undo log链表，等待purge线程进行最后的删除。 1.3.3. 回滚段 InnoDB在undo tablespace中使用回滚段来组织undo log。同时为了保证事务的并发操作，在写undo log时不产生冲突，InnoDB使用 回滚段 来维护undo log的并发写入和持久化；而每个回滚段 又有多个undo log slot。通常通过Rollback Segment Header来管理回滚段，Rollback Segment Header通常在回滚段的第一个页 Rollback Segment Header里面最重要的两部分就是history list与undo slot directory。 其中history list把所有已经提交但还没有被purge事务的undo log串联起来，purge线程可以通过此list对没有事务使用的undo log进行purge。 1.3.4. UndoPage undo page一般分两种情况：header page和normal page。 header page除了normal page所包含的信息，还包含一些undo segment信息 1.4. binlog 在引擎层的日志，用于主从同步。因为redolog时物理日志，且在引擎层之下，不适合作为主从复制。 为了保持redo log和binlog的一致性，使用两阶段提交。 保证 redo log 和 binlog 的操作记录一致的流程是，将操作先更新到内存，再写入 redo log，此时标记为 prepare 状态，再写入 binlog，此时再提交事务，将 redo log 标记为 commit 状态。 binlog存在三种形式：Statement、Row、Mixed。 Statement：就是把每一条SQL记录到binlog中。 Row：是把每一行修改的具体数据记录到binlog中。 Mixed：MySQL会灵活的区分，需要记录sql还是具体修改的记录。 只记录SQL的话binlog会比较小，但是有些SQL语句在主从同步数据的时候，可能会因为选择不同的索引在数据同步过程中出现数据不一致。记录Row的话就可以保证主从同步不会存在SQL语意偏差的问题，同时Row类型的日志在做数据恢复的时候也比较容易，但是Row会导致binlog过大。 1.5. 刷盘策略 0.每次事务提交不刷盘 1.每提交一次，刷一次盘 2.每提交n个事务，刷一次盘 如果保证不丢失数据，sync_binlog和innodb_flush_log_at_trx_commit的值都取为1。 1.5.1. redolog 和 binlog redo log 是InnoDB 引擎特有的；而 binlog 是MySQL Server 层实现的 redo log 是物理日志，记录的是“在某个数据页做了什么修改”；而 binlog 是逻辑日志，记录的是语句的原始逻辑。比如update T set c=c+1 where ID=2;这条SQL，redo log 中记录的是 ：xx页号，xx偏移量的数据修改为xxx；binlog 中记录的是：id = 2 这一行的 c 字段 +1 redo log 是循环写的，固定空间会用完；binlog 可以追加写入，一个文件写满了会切换到下一个文件写，并不会覆盖之前的记录 记录内容时间不同，redo log 记录事务发起后的 DML 和 DDL语句；binlog 记录commit 完成后的 DML 语句和 DDL 语句 作用不同，redo log 作为异常宕机或者介质故障后的数据恢复使用；binlog 作为恢复数据使用，主从复制搭建。 1.6. 两阶段提交 第一阶段prepare：先写redolog日志。 第二阶段commit：写binlog日志。 数据库宕机时会检查redolog状态，如果prepare，检查redolog和binlog是否一致，不一致则回滚。 1.7. 崩溃恢复 innodb的处理策略是：进行恢复时，从checkpoint开始，重做所有事务（包括未提交的事务和已回滚的事务），然后通过undo log回滚那些未提交的事务 By JNS0724            updated 2022-08-28 13:37:21 "},"数据库/mysql的buffer.html":{"url":"数据库/mysql的buffer.html","title":"mysql的buffer","keywords":"","body":"1. buffer1.1. doublewrite buffer1.1.1. 为什么redolog不能恢复页断裂1. buffer 1.1. doublewrite buffer mysql一个数据页是16k，操作系统是4k，16k会分四次持久化。如果写入一半时崩溃，就会有页断裂的风险。 bufferpool中的2MB内存，128个16k数据页。对应了共享表空间中的2MB磁盘空间。 脏页刷新的时候，会选择先写道doublewrite buffer中。 第1步：页数据先memcopy到DWB的内存里； 第2步：DWB的内存里的数据页，会先刷到DWB的磁盘上，顺序追加。8.0后可以指定存放目录，更快刷盘。 第3步：DWB的内存里的数据页，再刷到数据磁盘存储.ibd文件上。 如果系统的保证16k数据页的原子写入，可以不需要doublewrite，提升性能。 1.1.1. 为什么redolog不能恢复页断裂 redolog在崩溃恢复时，通过比较页中的LSN和自身的LSN来判断是新是旧，旧的才会重放。当页写入一半时，可能LSN信息改变但是数据没有刷新完。 除非每次重放都重放一个完整的事务。 By JNS0724            updated 2022-08-28 13:37:21 "},"数据库/mysql锁.html":{"url":"数据库/mysql锁.html","title":"mysql锁","keywords":"","body":"1. mysql的锁1.1. Gap Lock1.2. next-key lock1.3. MVCC1.3.1. 快照读1.4. 死锁1.5. 死锁检测1. mysql的锁 按锁的粒度分: 有行锁\\表锁. 按锁的使用方式有共享锁\\排他锁. innodb主要是这几种锁: Record Lock：在索引记录上加锁 Gap Lock：间隙锁 Next-key Lock：Record Lock + Gap Lock innodb在索引上加锁实现对一条记录的加锁,当使用一级索引查询时,只需要在主键索引上加锁,当使用二级索引时,先锁二级索引,再回表锁主键索引. innodb还有意向锁.是在存在行锁场景下的表锁快速失败机制。意向锁之间不互斥,意向锁和表锁互斥,由innodb默认加上. 1.1. Gap Lock 当我们使用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁;对于键值在条件范围内但并不存在的记录，InnoDB 也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁。 间隙锁和间隙锁之间是不互斥的,只阻塞插入数据,因为间隙锁只用来解决幻读问题. RR级别才生效,因为RC级别连可重复读都不保证,没有必要解决幻读问题(感觉是这个逻辑). 1.2. next-key lock gap+record,是前开后闭区间.如(5,10],最后一个加了行锁. 默认的加锁就是next-key lock锁机制,在具体sql执行的时候,会根据情况退化成间隙锁或者行锁. 索引就会有优化,比如说等值查询时只锁行锁,范围查询右边与条件不匹配时,只锁间隙锁. 普通字段查询就是全表加next-key lock 1.3. MVCC 多版本并发控制,主要是通过undolog和readview来解决并发过程中的读写冲突. 在RC和RR级别中启用. 底层实现时undo log的版本链和readview 通过readview获得当前活跃事务,这些事务会按照事务号从小到大排序,因为事务号是递增的所以隐含了时间顺序.对于活跃事务中,最小的是up_limt_id,小于它说明已经提交,则可见.另外有一个当前事务生成时最大的事务id参数,max_limit_id.大于它说明这个事务再当前事务之后,则不可见. 当在两者范围,则看是否存在于活跃事务中,存在的话就是未提交,当前不可见.否则可见. 1.3.1. 快照读 RC级别下,每次select生成一个快照 RR级别下,第一次select时,生成一个快照,后面的select复用这个快照. 在快照读下,不会有幻读问题. 1.4. 死锁 死锁产生的条件： 1.互斥 只能分配给一个进程 2.禁止抢占 资源不能强制从一个进程中退出 3.持有和等待：一个进程可以在等待时持有系统资源 4.循环等待：相互等待其他进程占有的资源 预防死锁必须破坏其中的一环。 mysql造成死锁的典型： 1.交互上锁，互相等待。 2.加了同一个区域的间隙锁，导致互相等待。 3.一个从主键索引开始锁，一个在二级索引开始锁，不同的加锁顺序，导致互相等待。 尽量缩小锁的范围，确定加锁的顺序，避免死锁。 1.5. 死锁检测 以事务为顶点，锁为边的有向图，判断有向图是否有环。 检测到死锁之后，选择插入更新或者删除的行数最少的事务回滚，基于 INFORMATION_SCHEMA.INNODB_TRX 表中的 trx_weight 字段来判断。 By JNS0724            updated 2022-08-28 13:37:21 "},"数据库/mysql高可用.html":{"url":"数据库/mysql高可用.html","title":"mysql高可用","keywords":"","body":"1. mysql 高可用1.1. 主从同步1.2. MHA模式1.3. MGR1. mysql 高可用 1.1. 主从同步 mysql可以通过binlog来实现主从同步. 有异步/同步/半同步几种方式,默认情况下是异步 半同步是5.5之后才出现的,性能和可靠性上取得平衡. 半同步模式：主库会等待至少有一个从库把数据写入relay log并ACK完成，才成功返回结果。 半同步模式介于异步和全同步之间。 半同步的复制方案是在MySQL5.5开始引入的，普通的半同步复制方案步骤如下图： Master节点写数据到Binlog，并且执行Sync操作。 Master发送数据给Slave节点，同时commit主库的事务。 收到ACK后Master节点把数据返回给客户端。 上面模式有点问题,主库先commit如果宕机会导致幻读.所以5.7改为先收到ack之后再commit主库事务. 1.2. MHA模式 MySQL Master High Availability, 只负责mysql主节点的高可用,主库发生故障时,会从从节点中选择一个成为主节点. 1.即使是主从同步,也有数据丢失的可能.对于主从同步的数据丢失,可以用binlog server,模拟slave节点接收binlog日志记录,每次写入都要等binlog server的ack应答,故障时从binlog server获取最新数据. 2.mha管理节点有单点问题,相当于我们又要考虑mha节点的可靠性.因此可以通过在mysql主从之中引入agent,发生故障时每个Agent均参与选举投票，选举出合适的Slave作为新的主库，防止只通过Manager来切换，去除MHA单点。 1.3. MGR 基于paxos或raft的分布式协议实现,当数据库发生故障时，MySQL内部自己进行切换。 相当于每次写入都要投票,半数以上ack了才写入,主节点挂掉之后由协议控制选主,把上面的两步都做到mysql的主从集群里. By JNS0724            updated 2022-08-28 13:37:21 "},"数据库/redis.html":{"url":"数据库/redis.html","title":"Redis","keywords":"","body":"1. redis1.1. 数据结构1.1.1. string1.1.2. list1.1.3. set1.1.4. hash1.1.5. zset1.2. 持久化1.2.1. RDB快照1.3. AOF1.3.1. AOF 重写1.4. RDB和AOF对比1.5. 作为缓存时的系列问题1.5.1. 缓存穿透1.5.2. 缓存击穿1.5.3. 缓存雪崩1.6. 缓存数据一致性1. redis 基于内存的kv数据库，由c实现 1.1. 数据结构 redis使用自身的类型系统： redisObject对象 基于 redisObject 对象的类型检查. 基于 redisObject 对象的显式多态函数. 对 redisObject 进行分配、共享和销毁的机制 一个redisobject包括以下这些属性： /* * Redis 对象 */ typedef struct redisObject { // 类型 unsigned type:4; // 编码方式 unsigned encoding:4; // LRU - 24位, 记录最末一次访问时间（相对于lru_clock）; 或者 LFU（最少使用的数据：8位频率，16位访问时间） unsigned lru:LRU_BITS; // LRU_BITS: 24 // 引用计数 int refcount; // 指向底层数据结构实例 void *ptr; } robj; /* * 对象类型 */ #define OBJ_STRING 0 // 字符串 #define OBJ_LIST 1 // 列表 #define OBJ_SET 2 // 集合 #define OBJ_ZSET 3 // 有序集 #define OBJ_HASH 4 // 哈希表 /* * 对象编码 */ #define OBJ_ENCODING_RAW 0 /* Raw representation */ #define OBJ_ENCODING_INT 1 /* Encoded as integer */ #define OBJ_ENCODING_HT 2 /* Encoded as hash table */ #define OBJ_ENCODING_ZIPMAP 3 /* 注意：版本2.6后不再使用. */ #define OBJ_ENCODING_LINKEDLIST 4 /* 注意：不再使用了，旧版本2.x中String的底层之一. */ #define OBJ_ENCODING_ZIPLIST 5 /* Encoded as ziplist */ #define OBJ_ENCODING_INTSET 6 /* Encoded as intset */ #define OBJ_ENCODING_SKIPLIST 7 /* Encoded as skiplist */ #define OBJ_ENCODING_EMBSTR 8 /* Embedded sds string encoding */ #define OBJ_ENCODING_QUICKLIST 9 /* Encoded as linked list of ziplists */ #define OBJ_ENCODING_STREAM 10 /* Encoded as a radix tree of listpacks */ redisOject对象池：共享字符串对象，如10000以内的数字 1.1.1. string 存储的值可以是字符串、整数或者浮点数 底层实现为char数组的封装，称为SDS。 结构基本为 |len|alloc|flags|buf| len是字符串的长度，alloc是分配的内存长度，flags标记头部类型，因为头部类型有uint8、u16，u32，u64几种类型。 扩容：小于1m则两倍扩容，大于1m则每次扩容1m，最大512m。 存储： 小于44个字符时，标志位为EMBSTR，sds与redisobject连续存储，大小为64B 大于44个字符时，标志位位RAW，使用ptr指针指向sds，当可以解析为数字时，标志位INT，存储与ptr指针内。 有点类似stl的string库。这种封装可以常数复杂度获取字符串长度，减少缓冲区溢出。 SDS有空间与分配和惰性空间释放两种策略。 空间与分配：对字符串进行空间扩展的时候，扩展的内存比实际需要的多，这样可以减少连续执行字符串增长操作所需的内存重分配次数。 惰性空间释放：对字符串进行缩短操作时，程序不立即使用内存重新分配来回收缩短后多余的字节，而是使用 alloc 属性将这些字节的数量记录下来，等待后续使用。 可以用来做缓存、session共享 1.1.2. list 底层：quicklist redis是内存数据库，相对于其他基于磁盘的，内存的空间比较紧缺。因此设计了压缩性质的ziplist 3.0之后list键已经不直接用ziplist和linkedlist作为底层实现了，取而代之的是quicklist ziplist是为了提高存储效率而设计的一种特殊编码的双向链表。它可以存储字符串或者整数，存储整数时是采用整数的二进制而不是字符串形式存储。它能在O(1)的时间复杂度下完成list两端的push和pop操作。但是因为每次操作都需要重新分配ziplist的内存，所以实际复杂度和ziplist的内存使用量相关。 ziplist以下这些属性 // ziplist结构 ... zlbytes 字段的类型是uint32_t, 这个字段中存储的是整个ziplist所占用的内存的字节数 zltail 字段的类型是uint32_t, 它指的是ziplist中最后一个entry的偏移量. 用于快速定位最后一个entry, 以快速完成pop等操作 zllen 字段的类型是uint16_t, 它指的是整个ziplit中entry的数量. 这个值只占2bytes（16位）: 如果ziplist中entry的数目小于65535(2的16次方), 那么该字段中存储的就是实际entry的值. 若等于或超过65535, 那么该字段的值固定为65535, 但实际数量需要一个个entry的去遍历所有entry才能得到. zlend 是一个终止字节, 其值为全F, 即0xff. ziplist保证任何情况下, 一个entry的首字节都不会是255 // prevlen：前一个entry的大小 // encoding: 当前entry的类型和长度 // 在entry中存储的是int类型时，encoding和entry-data会合并在encoding中表示 // 当前一个元素长度小于254（255用于zlend）的时候，prevlen长度为1个字节，值即为前一个entry的长度，如果长度大于等于254的时候，prevlen用5个字节表示，第一字节设置为254，后面4个字节存储一个小端的无符号整型，表示前一个entry的长度； // prevlen用来进行遍历访问 ziplist节省内存，但是内存分配频繁 ziplist不预留内存空间, 并且在移除结点后, 也是立即缩容 结点如果扩容, 导致结点占用的内存增长, 并且超过254字节的话, 可能会导致链式反应: 其后一个结点的entry.prevlen需要从一字节扩容至五字节. 最坏情况下, 第一个结点的扩容, 会导致整个ziplist表中的后续所有结点的entry.prevlen字段扩容。这就是ziplist的级联更新。 ziplist 不会预留扩展空间，每次插入一个新的元素就需要调用 realloc 扩展内存, 并可能需要将原有内容拷贝到新地址。 因为级联更新的现象的存在，添加、修改、删除元素操作的复杂度在 O(n) 到 O(n^2) 之间。 当作为list和hash的底层实现时，节点之间没有顺序；当作为zset的底层实现时，节点之间会按照大小顺序排列。 Quicklist 以ziplist为结点的双端链表结构. 宏观上, quicklist是一个链表, 微观上, 链表中的每个结点都是一个ziplist。 1.1.3. set 底层：hashtable或者intset 拉链法解决哈希冲突。扩容是两倍扩容，缩容也是缩小一倍。 渐进式hash 扩容和收缩操作不是一次性、集中式完成的，而是分多次、渐进式完成的。Redis采用渐进式 rehash,这样在进行渐进式rehash期间，字典的删除查找更新等操作可能会在两个哈希表上进行，第一个哈希表没有找到，就会去第二个哈希表上进行查找。但是进行 增加操作，一定是在新的哈希表上进行的。 typedef struct intset { uint32_t encoding; // 表示编码方式，的取值有三个：INTSET_ENC_INT16, INTSET_ENC_INT32, INTSET_ENC_INT64 uint32_t length; // 代表其中存储的整数的个数 int8_t contents[]; // 存储数据的buffer，int8_t就可以都支持上面三种类型 } intset; 往int16的intset里插入int32的数，会触发类型升级，所有的数都升级成int32。 1.1.4. hash 底层：hashtable或ziplist 适合用来存储一个完整的对象 1.1.5. zset 底层：ziplist或skiplist 查找时会从最顶层链表的头节点开始遍历，如果当前节点的下一个节点比目标值小，则继续向右查找，否则就向下一层查找。直到找到目标。 zset允许重复的 score 值：多个不同的 member 的 score 值可以相同。所以需要同时对比score和member。 跳表第k层的元素会按一定的概率p在第k+1层出现，这种概率性就是在插入过程中实现的。 插入时首先插入最底层，然后随机计算是否要插入第k层。 每个节点都带有一个高度为 1 层的后退指针，用于从表尾方向向表头方向迭代：当执行 ZREVRANGE 或 ZREVRANGEBYSCORE 这类以逆序处理有序集的命令时，就会用到这个属性。 1.2. 持久化 1.2.1. RDB快照 手动触发 save同步和bgsave异步 RDB Point-to-time snapshot，以二进制文件保存数据库某一时刻所有数据对象的内存快照。 RDB持久化的两个函数： rdbSave：同步执行，持久化过程会阻塞命令，无法对外提供服务。手动触发 rdbSaveBackground：定时通过fork子进程，子进程会拷贝父进程的内存数据，在子进程进行持久化保存内存对象，父进程数据变化不涉及子进程。 触发自动执行的场景： save m n配置规则自动触发 save命令就是redis的一个周期性函数，通过配置文件的规则来自动持久化。save m n的意思就是在m秒内有n此写入就触发 从节点全量复制时，主节点发送rdb文件给从节点，会触发主节点bgsave 执行debug reload命令重新加载redis 执行shutdow命令 如果服务器崩溃了，以上次的rdb完整文件做恢复。 1.3. AOF Aappend only file，redis的重放日志，追加式的日志文件。 每次修改类型的命令输入，就会追加到aof buffer，再写入aof文件。 由于内核缓冲区要等写满才同步到磁盘，可能会有丢数据风险。aof写入缓冲区后有三种策略： 每次都fsync同步 不刷新缓冲区 满足同步条件时调用fsync，理论上只会丢失1s的数据。 redis还有一个选项 no-appendfsync-on-rewrite 表示在AOF重写期间是否禁止调用fsync，默认为no 1.3.1. AOF 重写 简单的说就是AOF文件大小的压缩，当大小超过阈值时就会开始重写。通过内存数据对象的状态重写一份aof文件。 通过fork子进程，用RDB或者AOF的方式，先写入前半段，父进程通过匿名管道发送增量aof命令，追加到重写的aof buffer中。 1.4. RDB和AOF对比 RDB是数据快照，比起AOF的日志重放操作，数据恢复更快 AOF的数据更具有实时性，更新比较频繁。 RDB持久化过程内存占用大，AOF只是追加，更新快 1.5. 作为缓存时的系列问题 缓存穿透\\缓存击穿\\缓存雪崩\\缓存和数据一致性 1.5.1. 缓存穿透 一直访问缓存和数据库都没有的数据,导致每次都直接读数据库,给数据库造成IO压力. 解决: 1.从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null, 过期时间设置较短. 2.布隆过滤器 1.5.2. 缓存击穿 缓存击穿是指缓存中没有但数据库中有的数据 解决: 1.设置热点数据永远不过期 2.接口限流,熔断,失败快速返回 3.加锁 1.5.3. 缓存雪崩 缓存雪崩是指缓存中数据大批量到过期时间，而查询数据量巨大.缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库。 解决: 1.缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。 2.如果缓存数据库是分布式部署，将热点数据均匀分布在不同的缓存数据库中。 3.设置热点数据永远不过期。 1.6. 缓存数据一致性 By JNS0724            updated 2022-08-28 13:37:21 "},"数据库/redis分布式锁.html":{"url":"数据库/redis分布式锁.html","title":"redis分布式锁","keywords":"","body":"1. redis 分布式锁1. redis 分布式锁 分布式锁的关键： 1、达到互斥的要求 2、避免死锁，保证锁能释放 3、锁的性能 主要步骤： 1、用key做锁标记，value为用户标号写入redis。 2、当key不存在时写入，保证互斥。存在时则没获得锁。 3、设置过期时间，过期自动释放。 4、业务处理完后解锁 以上为redission加锁的步骤，其中一旦加锁成功，会有一个看门狗机制，自动对锁进行续期直到业务完成。 redission存在的问题主要在于主从架构有可能会因为主节点挂掉而导致锁信息丢失。对于这个问题，有redlock算法来尝试解决，对3个以上奇数个的master节点进行加锁请求，如果半数以上回复则加锁成功。（可以是N个单机节点，也可以是N个sentinel或者是N个cluster集群） By JNS0724            updated 2022-08-28 13:37:21 "},"数据库/数据库设计.html":{"url":"数据库/数据库设计.html","title":"数据库设计","keywords":"","body":"1. 数据库理论1.1. 并发控制1.1.1. 悲观锁1.1.2. 乐观锁1.2. 数据库恢复1.2.1. ARIES算法1. 数据库理论 来自于cmu15-445 1.1. 并发控制 为了保证事务之间执行的正确性，需要通过加锁策略来维护过程。加锁分为乐观锁和悲观锁。 1.1.1. 悲观锁 2PL 两阶段锁，分为growing和shrinking，在growing阶段只能加锁，在shrinking阶段只能解锁。 数据库的悲观锁通常有共享锁和排他锁，又可以称为读锁的写锁。读读兼容，读写、写写不兼容。 事务是一个一致性状态转移到另外一个一致性状态，通过两阶段锁，一次性给状态变更的资源加锁，再连续解锁，保证了一致性。 可能造成死锁，通过死锁检测和死锁预防来解决。 死锁预防 通过一个时间戳来给事务优先级，老的事务优先级通常较高。 当A申请资源锁的时 候，B已经获得了锁，有以下两个策略 wait-die: 不抢占，若A比B老，则等待B执行结束，若A比B年轻，A回滚。一段时间后会以原先的时间戳继续申请。 wound-wait: 有抢占，A比B年轻，A才等待，A比B老，则杀死B，B回滚。 保证事务执行是单向的，不循环等待。 死锁检测 优先去撤销当前已经执行过的更新次数最少的事务。保留那些已经运行了较长时间的事务。 如果事务等待的时间超过系统定义的超时时间，则系统假定事务可能死锁并中止它——不管死锁是否实际存在。 1.1.2. 乐观锁 1.2. 数据库恢复 1.2.1. ARIES算法 WAL with Steal/No-Force WAL机制 Fuzzy Checkpoints 模糊检查点 Redo everything since the earliest dirty page Undo txns that never commit Write CLRs when undoing, to survive failures during restarts Undo的时候记日志，即使宕机可以延续Undo By JNS0724            updated 2022-08-28 13:37:21 "},"计算机网络/传输层.html":{"url":"计算机网络/传输层.html","title":"传输层","keywords":"","body":"1. 传输层1.1. 端口号1.2. TCP协议1.2.1. TCP三次握手和四次挥手1.2.2. TCP 握手初始序列号1.2.3. 半连接队列和全连接队列1.2.4. TIME_WAIT 状态1.2.5. TCP重传机制1.2.6. 拥塞控制1.2.7. keepAlive1.3. UDP1.3.1. TCP和UDP的区别1.3.2. 总结1.3.3. UDP首部1.3.4. UDP校验1. 传输层 实现不同主机之间进程端到端的通信。 1.1. 端口号 在IP的基础上，新增了端口号的标识，在TCP/IP协议簇中，端口号是在0到65535之间的16 位整数。 熟知端口。端口号的范围是0~1023，由ICANN 分配和控制。这些是熟知端口号。 注册端口。端口号的范围是1024~49151，ICANN 不分配也不控制。它们可在ICANN 注册以防重复。 动态端口。端口号的范围是49152~65535。这一范围内的端口号既不受控制又不需要注册，可以由任何进程使用。它们是临时或私有端口号。 1.2. TCP协议 传输控制协议 TCP（Transmission Control Protocol）是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块），每一条 TCP 连接只能是点对点的（一对一）。 1.2.1. TCP三次握手和四次挥手 1.2.2. TCP 握手初始序列号 TCP初始化序列号不能设置为一个固定值，因为这样容易被攻击者猜出后续序列号，从而遭到攻击。 RFC1948中提出了一个较好的初始化序列号ISN随机生成算法。 ISN = M + F(localhost, localport, remotehost, remoteport). M是一个计时器，这个计时器每隔4毫秒加1。 F是一个Hash算法，根据源IP、目的IP、源端口、目的端口生成一个随机数值。 1.2.3. 半连接队列和全连接队列 tcp服务端创建连接时需要用两个队列，分别存储 SYN_RCVD 状态的连接和 ESTABLISHED 状态的连接，这就是半连接队列和全连接队列。 1、半连接队列有可能遇到攻击，即客户端大量发送syn但不回复服务端的syn+ack。 半连接队列的大小与三个值有关： 用户层 listen 传入的backlog 系统变量 net.ipv4.tcp_max_syn_backlog，默认值为 128 系统变量 net.core.somaxconn，默认值为 128 内核协议栈有一个优化，通过发送syn+ack和一个cookie来确认对面是不是正常用户。 2、全连接队列满了，通常发生在请求过多，来不及处理的情况。或者accept太慢了。 全连接队列的大小是 listen 传入的 backlog 和 somaxconn 中的较小值。 正常情况，从半连接队列取出连接，然后放入全连接队列。 这时全连接队列满了，如果设置了 net.ipv4.tcp_abort_on_overflow。就回复RST，删除对应半连接。否则不回复，一段时间后重发syn+ack. 全连接队列满了对于客户端来说是不感知的，所以如果客户端这时发送数据来的话，这时服务端会回复RST或者不回复。 1.2.4. TIME_WAIT 状态 TIME_WAIT 仅在主动断开连接的一方出现，被动断开连接的一方会直接进入 CLOSED 状态，进入 TIME_WAIT 的客户端需要等待 2 MSL 才可以真正关闭连接。 防止延迟的数据段被其他使用相同源地址、源端口、目的地址以及目的端口的 TCP 连接收到； 在默认情况下，如果客户端等待足够长的时间就会遇到以下两种情况： 服务端正常收到了 ACK 消息并关闭当前 TCP 连接； 服务端没有收到 ACK 消息，重新发送 FIN 关闭连接并等待新的 ACK 消息； 只要客户端等待 2 MSL 的时间，客户端和服务端之间的连接就会正常关闭，新创建的 TCP 连接收到影响的概率也微乎其微，保证了数据传输的可靠性。 1.2.5. TCP重传机制 两种重传：超时重传（选择重传）、快重传 超时重传 RTO 定时器的等待时间称为RTO（Retransmission Timeout 超时重传时间） RTT 数据从网络一端传送到另一端往返所需的时间称为RTT（Round-Trip Time 往返时延） 重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 ACK 确认应答报文，就会重发该数据，也就是常说的超时重传。 当超时时间 RTO 较大时，一个RTT结束之后可能还要继续等待，传输效率降低。 当超时时间 RTO 较小时，导致多传包，会增加网络拥塞。 根据上述的两种情况，可以得知，超时重传时间 RTO 的值应该略大于报文往返 RTT 的值。Linux 是如何计算 RTO 的呢？ 需要 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个平滑 RTT 的值，而且这个值还是要不断变化的，因为网络状况不断地变化。 除了采样 RTT，还要采样 RTT 的波动范围，这样就避免如果 RTT 有一个大的波动的话，很难被发现的情况。 如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是超时间隔加倍。 也就是每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。 快速重传 为TCP等待一定数目的重复ACK（称为重复ACK阈值或dupthresh），来决定数据是否丢失并触发快速重传。通常dupthresh为常量（值为3），但是linux系统可基于当前的失序程度动态调节该值。 对于重传的包，有两种选择 一种是仅重传timeout的包。 另一种是重传timeout后所有的数据。 1.2.6. 拥塞控制 慢启动 拥塞避免 快重传 接收方收到一个失序的报文段就发出重复确认，发送方一连收到三个重复确认就重传对方未确认收到的报文段 快速恢复 发送方收到三个重复确认就把cwnd设置为ssthresh门限减半后的数值、开始执行拥塞避免。 1.2.7. keepAlive 一段时间后发送探测报文，没反应则主动关闭连接。 TCP的KeepAlive机制意图在于保活、心跳，检测连接错误 HTTP协议的Keep-Alive意图在于连接复用，同一个连接上串行方式传递请求-响应数据 1.3. UDP 1.3.1. TCP和UDP的区别 基于连接与无连接 TCP要求系统资源较多，UDP较少 UDP程序结构较简单 流模式（TCP）与数据报模式(UDP) TCP保证数据正确性，UDP可能丢包 TCP保证数据顺序，UDP不保证 1.3.2. 总结 UDP基于无连接，不需要握手，不需要状态机维护状态。 UDP首部开销小，只有8个字节。 UDP不保证可靠传输，可能会丢包，但响应速度较快。 UDP面向报文，添加首部后直接乡下交付为IP层，既不合并，也不拆分，保留这些报文的边界。对IP层交上来UDP用户数据报，在去除首部后就原封不动地交付给上层应用进程，报文不可分割，是UDP数据报处理的最小单位。 1.3.3. UDP首部 源端口: 占16位、源端口号。在需要对方回信时选用。不需要时可用全0。 目的端口: 占16位、目的端口号。这在终点交付报文时必须使用。 长度: 占16位、UDP用户数据报的长度,其最小值是8(仅有首部)。 检验和: 占16位、检测UDP用户数据报在传输中是否有错。有错就丢弃。 1.3.4. UDP校验 UDP校验和的计算方法和IP数据报首部校验和的计算方法相似，都使用二进制反码运算求和再取反，但不同的是：IP数据报的校验和之检验IP数据报和首部，但UDP的校验和是把首部和数据部分一起校验。 By JNS0724            updated 2022-08-28 13:37:21 "},"计算机网络/应用层.html":{"url":"计算机网络/应用层.html","title":"应用层","keywords":"","body":"1. 应用层1.1. HTTP1.1.1. get和Post的区别1.1.2. HTTP状态码1.1.3. cookie1.1.4. session1.1.5. HTTPS1.2. DNS解析1.3. Https1.4. HTTP1.11.5. HTTP2.01.6. HTTP3.01.7. DHCP协议1. 应用层 1.1. HTTP 1.1.1. get和Post的区别 get的参数放在url里面、post的参数放在请求体里面 get请求会被游览器缓存、post请求不会缓存 get请求只响应一次、游览器把HTTP header和data一起发送出去、服务器相应200、post相应两次，游览器先发送header,服务器相应100continue,游览器再发送data、服务器相应200。 https://github.com/febobo/web-interview/issues/145 1.1.2. HTTP状态码 状态码 类别 原因短语 1XX Informational(信息性状态码) 接收的请求正在处理 2XX Success(成功状态码) 请求正常处理完毕 3XX Redirection(重定向状态码) 需要进行附加操作以完成请求 4XX Client Error(客户端错误状态码) 服务器无法处理请求 5XX Server Error(服务器错误状态码) 服务器处理请求出错 1.1.3. cookie Cookie HTTP 协议是无状态的，主要是为了让 HTTP 协议尽可能简单，使得它能够处理大量事务。HTTP/1.1 引入 Cookie 来保存状态信息。 Cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器之后向同一服务器再次发起请求时被携带上，用于告知服务端两个请求是否来自同一浏览器。由于之后每次请求都会需要携带 Cookie 数据，因此会带来额外的性能开销(尤其是在移动环境下)。 1.1.4. session 除了可以将用户信息通过 Cookie 存储在用户浏览器中，也可以利用 Session 存储在服务器端，存储在服务器端的信息更加安全。 Session 可以存储在服务器上的文件、数据库或者内存中。也可以将 Session 存储在 Redis 这种内存型数据库中，效率会更高。 1.1.5. HTTPS HTTPs 并不是新协议，而是让 HTTP 先和 SSL(Secure Sockets Layer)通信，再由 SSL 和 TCP 通信，也就是说 HTTPs 使用了隧道进行通信。 1.2. DNS解析 1、本地客户机提出域名解析请求，查找本地HOST文件后将该请求发送给本地的域名服务器。 2、将请求发送给本地的域名服务器。 3、当本地的域名服务器收到请求后，就先查询本地的缓存。 4、如果有该纪录项，则本地的域名服务器就直接把查询的结果返回浏览器。 5、如果本地DNS缓存中没有该纪录，则本地域名服务器就直接把请求发给根域名服务器。 6、然后根域名服务器再返回给本地域名服务器一个所查询域（根的子域）的主域名服务器的地址。 7、本地服务器再向上一步返回的域名服务器发送请求，然后接受请求的服务器查询自己的缓存，如果没有该纪录，则返回相关的下级的域名服务器的地址。 8、重复第7步，直到找到正确的纪录。 9、本地域名服务器把返回的结果保存到缓存，以备下一次使用，同时还将结果返回给客户机。 递归查询：主机向本地域名服务器的查询一般都是采用递归查询。如果主机所询问的本地域名服务器不知道被查询的域名的 IP 地址，那么本地域名服务器就以 DNS 客户的身份，向其它根域名服务器继续发出查询请求报文(即替主机继续查询)，而不是让主机自己进行下一步查询。因此，递归查询返回的查询结果或者是所要查询的 IP 地址，或者是报错，表示无法查询到所需的 IP 地址。 迭代查询：一般DNS服务器之间属迭代查询，如：若 DNS2 不能响应 DNS1 的请求，则它会将 DNS3 的 IP 给 DNS2，以便其再向 DNS3 发出请求。 1.3. Https 在传输层和应用层之间，增加了TLS和SSL的握手和协商加密协议。 在这里分为非对称加密和对称加密，服务器先给客户端发送公钥和数字证书，客户端通过数字证书对公钥进行一些hash操作，验证是否于数字证书中的数字签名一致，如果一致则公钥认证通过。然后客户端自己会生成一个密钥，用公钥加密自己的密钥发到服务端，服务端用私钥解锁公钥获得密钥。后面的通信全都采用密钥。 总结：非对称加密里套了一层对称加密。 1.4. HTTP1.1 比起Http1.0 1.增加了keep-alive属性，保持了tcp长连接，多个请求可以复用一个连接。 对于一个域名，浏览器最多可以开启4到6个长连接，不同浏览器限制不同。 2.用流模式取代了缓存模式。 3.新增了PUT、DELETE等请求方式。 缺点：多个请求排队，会有阻塞的情况 1.5. HTTP2.0 二进制分帧层，可以将报文转换为二进制。 多路复用，1.1可以并行发送请求，但返回响应结果必须是发送的顺序。多路复用的基础是二进制分帧，可以乱序发送和接收。 多路复用的实现基于二进制帧和流的概念，即把有数据依赖的分到一个流里，不同流互相不影响。 首部压缩：维护一张静态表和动态表，静态表是常见的头部，动态表是变化的首部信息。 1.6. HTTP3.0 由于http2.0基于tcp，tcp数据包丢失时会阻碍滑动窗口移动。 递增的序号，通过偏移来组装报文。每个请求使用一个滑动窗口，单个丢包时不影响其他stream。 两级流量控制：connection规定所有数据流的总窗口大小，stream规定每个流的窗口大小。 应用层的拥塞控制：慢启动、拥塞避免、拥塞发生、快速恢复 前向安全和前向纠错，每当发送一组数据，就对其进行异或操作，将结果发送到对端进行比对，可以对初始数据进行纠错和校验。 1.7. DHCP协议 端口67 68 主机通过广播查找DHCP服务器。 DCHP服务器收到后，会分配一个IP地址，并广播。 主机收到DHCP广播的报文后，单播DHCP服务器。 DHCP回应主机，缓存主机信息。 DCHP可以认为是基于UDP的应用层协议，但本质是为了寻求新主机的动态ip地址。 By JNS0724            updated 2022-08-28 13:37:21 "},"计算机网络/数据链路层.html":{"url":"计算机网络/数据链路层.html","title":"数据链路层","keywords":"","body":"1. 数据链路层1.1. 信道类型1.2. 基本功能1.2.1. 链路管理1.2.2. 封装成帧1.2.3. 透明传输1.2.4. 差错校验1.2.5. 流量控制和可靠传输1.3. 点对点协议1.3.1. HDLC协议1.3.2. PPP协议1.4. 广播信道1.4.1. CSMA/CD 协议1.5. 数据链路层主要网络设备1.5.1. 网卡1.5.2. 网桥1.5.3. 交换机1.5.4. 交换机与网桥的区别1.5.5. Linux下的虚拟网桥1. 数据链路层 物理层构建了网络的物理通道，数据链路层在物理层的基础上，构建了逻辑链路。具体的如局域网中的以太网链路，广域网中的数据链路。 数据链路层提供差错检测和流量检测功能，将物理层的比特流解析成帧结构。 数据链路层屏蔽的物理介质的差异，提供具有协议约定的逻辑通道。 数据链路层的主体在网络适配器实现， 协议主要有PPP协议、以太网的CSMA/CD协议、OSI的HDLC协议。 1.1. 信道类型 数据链路层使用的信道主要有两种类型： 点对点信道 广播信道 1.2. 基本功能 1.2.1. 链路管理 数据链路层有三种基本服务。 无确认的无连接服务，有确认的无连接服务，有确认的有连接服务。 链路管理主要是负责链路的建立，维护和释放。主要面向有连接的服务。 1.2.2. 封装成帧 在帧的前后添加头部和尾部，界定帧的边界。MTU就是帧的数据部分的最大长度，也就是IP数据报的最大长度。 帧的作用主要在于对底层比特流数据的逻辑定义，并且提供帧定界功能 1.2.3. 透明传输 透明传输是指数据链路层对上层交付的传输数据并没有任何限制，就好像数据链路层不存在一样 其主要解决的问题就是在帧数据中，包含了帧头或帧尾的信息，接收方该如何判别这是定界信息还是数据的问题。 字符计数法 字符计数法是用一个特殊的字符来表示一帧的开始，然后用一个计数字段来表明该帧包含的字节数。 很少看到。 零比特填充法（HDLC协议、PPP协议） 使用01111110作为帧的开始和结束标志，如果帧数据部分出现01111110（即连续的6个“1”），只要数据帧检测到有5个连续的“1”，马上在其后插入“0” 字符填充法 SOH是帧首部的第一个标记开始的字节，EOT是帧尾部的结束字节，有了这两个字节，接收端就能够判断帧接收的开始位置和结束位置。 违规编码法 在曼切斯特编码中，每一个比特对应的电频都是对应“高-低”或者“低-高”，不会出现“高-高”或者“低-低”这两种编码方式，因此这两种编码方式就是两种违规的编码方法。 1.2.4. 差错校验 CRC循环冗余校验 根本思想就是先在要发送的帧后面附加一个数（这个数就是用来校验的校验码，也是二进制序列的），生成一个新帧发送给接收端。当然，这个附加的数不是随意的，它要使所生成的新帧能与发送端和接收端共同选定的某个特定数整除。 1.2.5. 流量控制和可靠传输 在OSI（HDLC）中，数据链路层存在流量控制和可靠传输。而在TCP/IP（常用PPP和CSMA/CD）中，数据链路层的流量控制和可靠传输，在传输层中进行。 停止-等待协议SW 全双工通信，发送缓存和接收缓存传输速率不一致的问题。每发送完一个帧就停止发送,等待对方的确认,在收到确认后再发送下一个帧。或超时计时器到时间后，才进行下一个帧的发送。信道利用率低。 回退N帧协议GBN 选择重传协议SR 1.3. 点对点协议 1.3.1. HDLC协议 高级数据链路控制协议，在数据链路层上实现了可靠传输，牺牲了一定性能，在过去通信链路质量差的时候使用。 支持面向连接和面向无连接 支持点对点和点对多点 支持半双工和全双工 支持流量控制和差错控制 HDLC的帧格式规定以01111110（十六进制7E）的位组合作为它的起始和结束的标志，用零比特填充法来实现透明传输。 1.3.2. PPP协议 PPP (Point-to-Point Protocol，点对点协议）是一种应用非常广泛的广域网数据链路层协议。在以太网运行的PPP协议来进行用户认证和接入的称为PPPoE协议。 1.4. 广播信道 主要用于局域网，局域网应用最广泛的就是我们熟悉的以太网。 以太网提供服务是不可靠的交付，即最大努力的交付；当接收站收到的有差错的数据帧时就丢弃此帧，其它什么也不做，差错的纠正由高层来处理；如果高层发现丢失了一些数据而进行重传，但以太网并不知道这是一个重传的帧，而是当作一个新帧发送。 以太网使用星型的网络拓扑结构，在星形的中心增加了一种可靠性高的设备，为集线器(hub)。 1.4.1. CSMA/CD 协议 1.5. 数据链路层主要网络设备 1.5.1. 网卡 网卡是一块被设计用来允许计算机在计算机网络上进行通讯的计算机硬件。由于其拥有MAC地址，因此属于OSI模型的第1层和2层之间。它使得用户可以通过电缆或无线相互连接。 每一个网卡都有一个被称为MAC地址的独一无二的48位串行号，它被写在卡上的一块ROM中。在网络上的每一个计算机都必须拥有一个独一无二的MAC地址。 1.5.2. 网桥 网桥（Bridge）是早期的两端口二层网络设备。网桥的两个端口分别有一条独立的交换信道，不是共享一条背板总线，可隔离冲突域。网桥比集线器（Hub）性能更好，集线器上各端口都是共享同一条背板总线的。后来，网桥被具有更多端口、同时也可隔离冲突域的交换机所取代。 网桥初期主要用于局域网LAN分段、传输距离延伸和增加应用设备，并使局域网突破共享网络带宽的限制。为了能够使局域网LAN满足当时的应用需求，需要扩展局域网系统。同时，为了使网络系统运行更可靠，把一个局域网系统划分为若干个独立的物理网段。实现物理网段之间的连接和扩展局域网系统的需求导致了网桥的发展。 1.5.3. 交换机 交换机是主导网络系统的集线设备，大部分交换机是在OSI参考模型的数据链路层（第二层）操作。如果把集线器看成一条内置的以太网总线，交换机就可以看做由多条总线构成交换矩阵的互联系统。 1.5.4. 交换机与网桥的区别 局域网交换机的基本功能与网桥一样，具有帧转发、帧过滤和生成树算法功能。但是，交换机与网桥相比还是存在以下不同： 交换机工作时，实际上允许许多组端口间的通道同时工作。所以，交换机的功能体现出不仅仅是一个网桥的功能，而是多个网桥功能的集合。即网桥一般分有两个端口，而交换机具有高密度的端口。 分段能力的区别 由于交换机能够支持多个端口，因此可以把网络系统划分成为更多的物理网段，这样使得整个网络系统具有更高的带宽。而网桥仅仅支持两个端口，所以，网桥划分的物理网段是相当有限的。 传输速率的区别 交换机与网桥数据信息的传输速率相比，交换机要快于网桥。 数据帧转发方式的区别 网桥在发送数据帧前，通常要接收到完整的数据帧并执行帧检测序列FCS后，才开始转发该数据帧。交换机具有存储转发和直接转发两种帧转发方式。直接转发方式在发送数据以前，不需要在接收完整个数据帧和经过32bit循环冗余校验码CRC的计算检查后的等待时间。 1.5.5. Linux下的虚拟网桥 网桥是在内核中虚拟出来的，可以将主机上真实的物理网卡（如eth0，eth1），或虚拟的网卡（tap0,tap1,vnet0,vnet1)桥接上来。桥接上来的网卡就相当于网桥上的端口。 端口收到的数据包都提交给这个虚拟的”网桥“，让其进行转发。 By JNS0724            updated 2022-08-28 13:37:21 "},"计算机网络/网络层.html":{"url":"计算机网络/网络层.html","title":"网络层","keywords":"","body":"1. 网络层1.1. 功能1.2. 虚电路和数据报网络1.3. 主要协议1.4. 路由转发1.4.1. 路由选择1.4.2. 分组转发1.5. 拥塞控制1.5.1. 流量感知路由1.5.2. 准入控制1.5.3. 流量调节1.5.4. 负载脱落1.6. IP协议1.6.1. IP地址1.6.2. 其他地址分类1.6.3. CIDR1.6.4. 子网掩码1.6.5. NAT1.6.6. IP报文1.7. ARP协议1.8. ICMP协议1.9. DHCP协议1. 网络层 1.1. 功能 网络层主要解决异构网络互联、路由转发、拥塞控制。 1.2. 虚电路和数据报网络 数据报网络提供网络层的无连接服务。 虚电路网络提供网络层的连接服务。 1.3. 主要协议 IP、ARP、ICMP、IGMP 1.4. 路由转发 1.4.1. 路由选择 根据特定路由选择协议构造出路由表定期和相邻的路由表交换信息，更新路由表。 1.4.2. 分组转发 根据转发表将用户IP数据报转发到合适的端口。 1.5. 拥塞控制 用户对网络资源（包括链路带宽、存储空间和处理器处理能力等）的总需求超过了网络固有的容量。 发生拥塞的原因： 缓冲区容量有限 传输线路的带宽有限 网络结点的处理能力有限 网络中某些部分发生了故障 1.5.1. 流量感知路由 网络抽象为一张带权无向图， 路由器抽象为图的结点， 链路抽象为图的边，每一条链路有自己的链路费用（例如：时延小，权值小）。权值根据网络负载动态调整， 可以将网络流量引导到不同的链路上， 均衡网络负载。 1.5.2. 准入控制 对新建虚电路审核，如果新建立的虚电路会导致网络变得拥塞，那么网络拒绝建立该新虚电路。 1.5.3. 流量调节 流量调节：在网络发生拥塞时，通过调整发送方发送数据的速率来消除拥塞。 抑制分组：感知到拥塞的路由器选择一个被拥塞的数据报，给该数据报的源主机返回一个抑制分组。背压：抑制分组在从拥塞结点到源结点的路径上的每一跳，都发挥抑制作用。 1.5.4. 负载脱落 负载脱落：有选择地主动丢弃一些数据报，来减轻网络负载，从而缓解或消除拥塞。 1.6. IP协议 无连接的、不可靠的、尽力的数据报投递服务。每个数据链路上会规定一个最大传输单元MTU，如果 IP 数据报的长度超过 MTU，那么网络层就会把这些报文分割成一个一个的小组（分组）进行传送，以适应具体的传输网络。 1.6.1. IP地址 IP地址类别 网络号 网络范围 主机号 IP地址范围 A 类 8bit，第一位固定为 0 0 —— 127 24bit 1.0.0.0 —— 127.255.255.255 B 类 16bit，前两位固定为 10 128.0 —— 191.255 16bit 128.0.0.0 —— 191.255.255.255 C 类 24bit，前三位固定为 110 192.0.0 —— 223.255.255 8bit 192.0.0.0 —— 223.255.255.255 D 类 前四位固定为 1110，后面为多播地址 E 类 前五位固定为 11110，后面保留为今后所用 1.6.2. 其他地址分类 网络号全0，但主机号非全0的某个ip就是指本网络的某个主机 网络号不为全1，但主机号全为1的ip，则指某个网络的广播地址 全0，指本网络的本主机 全1，指本网络的广播地址 环回地址，指127.0.0.1，在同一台主机上进行网络传输 私有地址，指不会参与路由器转发的地址,， 只会参与本局域网，发给本局域网的交换机： A类： 10.0.0.0-10.25.255.255 B类： 172.16.0.0-172.31.0.0 C类： 192.168.0.0-192.168.255.255 1.6.3. CIDR IP地址 ::= {， ， } 128.14.35.7/20 ， 完整ip加子网位数 10.0.0.0/10 -> 10/10， 可省略末尾的0 00010100*， 即用星号代替子网后的主机号 1.6.4. 子网掩码 值1的位置指该ip中该位置是网络号和子网号区域 值0的位置指该ip中该位置是主机号区域。 路由寻址时，一般先比较网络号，再比较子网号，再比较主机。 1.6.5. NAT 用于在本地网络中使用私有地址，在连接互联网时使转而使用全局 IP 地址的技术。实现网络地址转换的关键就在于 NAT 路由器。在 NAT 路由器的内部，有一张自动生成的用来转换地址的表。 1.6.6. IP报文 20个字节的首部长度 分片和重组 分片问题一般只存在于具有不同MTU值的互联网中，把一个数据报为了适合网络传输而分成多个数据报的过程称为分片，当分了片的IP数据报到达最终目标主机时，目标主机对各分片进行组装，恢复成源主机发送时的IP数据报。 MTU：数据链路帧的数据区的最大字节数 1.7. ARP协议 根据IP地址获得对方的MAC地址。 检查自身ARP缓存表 发送ARP request广播报文，ARP请求报文中的发送端IP地址和发送端MAC地址为主机A的IP地址和MAC地址，目标IP地址和目标MAC地址为主机B的IP地址和全0的MAC地址。 主机B以单播方式发送ARP响应报文给主机A，其中包含了自己的MAC地址。 主机A收到ARP响应报文后，将主机B的MAC地址加入到自己的ARP表中以用于后续报文的转发。 当主机A和主机B不在同一网段时，主机A就会先向网关发出ARP请求，然后把帧的目的mac地址改成网关的，把数据包发到网关。当网关解析到ip协议时，发现目的ip不是自己，就重新封装成帧，发到下一跳路由。 因此ARP协议是网络层协议，因为涉及到网络层路由转发到对应子网。 1.8. ICMP协议 网络控制报文协议，封装在IP的数据报文中。 发送网络层之间的差错报告。 1.9. DHCP协议 主机通过广播查找DHCP服务器。 DCHP服务器收到后，会分配一个IP地址，并广播。 主机收到DHCP广播的报文后，单播DHCP服务器。 DHCP回应主机，缓存主机信息。 DCHP可以认为是基于UDP的应用层协议，但本质是为了寻求新主机的动态ip地址。 By JNS0724            updated 2022-08-28 13:37:21 "},"计算机网络/计算机网络体系.html":{"url":"计算机网络/计算机网络体系.html","title":"计算机网络体系","keywords":"","body":"1. 计算机网络体系1.1. OSI七层结构1.2. 五层网络和Tcp/IP四层网络结构1. 计算机网络体系 1.1. OSI七层结构 应用层：应用自定义协议，Http、Ftp等协议 表示层：数据的表示、安全、压缩。格式有，JPEG、ASCll、DECOIC、加密格式等 会话层：建立、管理、终止会话。对应主机进程，指本地主机与远程主机正在进行的会话 传输层：定义传输数据的协议端口号，以及流控和差错校验。协议有：TCP UDP，数据包一旦离开网卡即进入网络传输层 网络层：进行逻辑地址寻址，实现不同网络之间的路径选择。协议有：ICMP IGMP IP（IPV4 IPV6） ARP RARP 数据链路层：建立逻辑连接、进行硬件地址寻址、差错校验等功能。将比特组合成字节进而组合成帧，用MAC地址访问介质，错误发现但不能纠正。 物理层：建立、维护、断开物理连接。 1.2. 五层网络和Tcp/IP四层网络结构 应用层：应用层协议定义的是应用进程间通信和交互的规则 运输层：运输层的任务就是负责向两台主机中进程之间的通信提供通用的数据传输服务 网络层：把运输层产生的报文段或用户数据报封装成分组或包进行传送 数据链路层：将网络层交下来的 IP 数据报组装成帧，并在两个相邻结点间的链路上传送 物理层：利用物理媒体以比特形式传送数据 Tcp/IP协议栈中，数据链路层和物理层合为网络接口层。 By JNS0724            updated 2022-08-28 13:37:21 "}}